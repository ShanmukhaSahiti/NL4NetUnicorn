# NL4NetUnicorn

This project uses Retrieval Augmented Generation (RAG) to convert natural language prompts into netUnicorn Python code for data collection tasks.


## Features

- Converts natural language prompts to netunicorn Python code
- Supports various data collection tasks
- Generates well-documented, production-ready code
- Uses RAG to understand context from documentation and examples
- Feedback loop for automatic error correction
- Automatic script execution and result reporting

## Setup

1. Clone directory:
```bash
git clone https://github.com/ShanmukhaSahiti/NL4NetUnicorn.git
```

2. Create a virtual environment and activate it:
```bash
python -m venv venv
source venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the root directory `(NL4NetUnicorn/)` with your OpenAI API key and netUnicorn login credentials:
```
NETUNICORN_ENDPOINT = your_endpoint_here
NETUNICORN_LOGIN = your_login_here
NETUNICORN_PASSWORD = your_password_here
OPENAI_API_KEY = your_api_key_here
```

## Usage

1. To generate code for a single prompt:
```bash
python generate_netunicorn_script.py -p "Create a NetUnicorn script that connects to the server, selects one available node, and runs a sleep task for 10 seconds. Ensure all results are printed." [options]
```
### Command-line Arguments

- `-p, --prompt`: (Required) The natural language prompt describing the NetUnicorn script you want to generate
- `-s, --save_script`: (Optional) Disable saving the generated script (default is to save)
- `-f, --feedback_loop`: (Optional) Disable feedback loop (default is enabled)
- `-r, --retries`: (Optional) Maximum number of retries for the feedback loop. Default = 3.

For example, to generate code for a single sleep task where the final script is not saved and with 4 retries:
```bash
python generate_netunicorn_script.py "Create a NetUnicorn script that connects to the server, selects one available node, and runs a sleep task for 10 seconds. Ensure all results are printed." -s -r 4
```

2. To generate code for one or more prompts and view an evaluation report:
```bash
python evaluate_rag.py -i "file containing one prompt on each line"
```
Use the `-s`, `-f`, and `-r` flags accordingly.

### 3. Evaluating Retrieved Context Aptness (LLM as Judge)

To specifically evaluate the quality of the context retrieved by the RAG system for a given prompt, you can use the `judge_evaluate_retrieved_context.py` script. This script employs another LLM (the "judge") to analyze if the retrieved documentation chunks are relevant, sufficient, and helpful for generating the requested NetUnicorn script. It also extracts numerical scores for these aspects if the judge LLM provides them in the expected format.

**How it Works:**

1.  You provide a natural language prompt.
2.  The script uses the `NetUnicornRAG` system to fetch the most relevant context chunks from the documentation (`nl4netunicorn_llm/data/netunicorn_docs.json` by default).
3.  These chunks, along with your original prompt, are presented to an LLM judge.
4.  The judge evaluates the context based on relevance, sufficiency, and helpfulness, providing a textual assessment and scores.

**To run the context evaluation:**

```bash
python judge_evaluate_retrieved_context.py -p "Your natural language prompt here" [options]
```

**Command-line Arguments for `judge_evaluate_retrieved_context.py`:**

*   `-p, --prompt`: (Required) The natural language prompt to evaluate context for.
*   `--docs_path`: (Optional) Path to the NetUnicorn documentation JSON file. Defaults to `nl4netunicorn_llm/data/netunicorn_docs.json`.
*   `--judge_model_name`: (Optional) The OpenAI model name for the LLM judge (e.g., `gpt-3.5-turbo`, `gpt-4`). Defaults to `gpt-3.5-turbo`.
*   `-k, --num_chunks`: (Optional) Number of top context chunks to retrieve and show to the judge. Defaults to 3.

**Example:**

```bash
python judge_evaluate_retrieved_context.py \
    -p "Create a NetUnicorn script to run a ping to 'google.com' from one node and print the results." \
    --judge_model_name "gpt-4-turbo" \
    -k 5
```

This will output the original prompt, the retrieved context chunks, the LLM judge's detailed textual assessment, and any extracted scores. Ensure your `OPENAI_API_KEY` is set in the `.env` file.

## Project Structure

- `data/`: Context for RAG system
  - `netunicorn_docs.json`
- `examples/`: Example usage scripts
- `src/`: Source code for the RAG system
  - `feedback_handler.py`
  - `netunicorn_rag.py`: Main RAG implementation
  - `script_executor.py`: Executes scripts generated by LLM
- `evaluate_rag.py`: Generates evaluation reports
- `generate_netunicorn_script.py`: Generates netUnicorn script for one prompt
- `judge_evaluate_retrieved_context.py`: Evaluates RAG retrieved context aptness using an LLM judge.