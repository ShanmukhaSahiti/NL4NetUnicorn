[
  {
    "source": "NetUnicorn Basic Client Usage",
    "content": "To interact with NetUnicorn, you first need to create a RemoteClient instance. Example: \nfrom netunicorn.client.remote import RemoteClient\nclient = RemoteClient(endpoint='your_endpoint', login='your_login', password='your_password')\nclient.healthcheck() can be used to verify the connection."
  },
  {
    "source": "NetUnicorn Experiment Basics",
    "content": "An Experiment in NetUnicorn maps a Pipeline to a set of nodes. Example: \nfrom netunicorn.base.experiment import Experiment\nfrom netunicorn.base.pipeline import Pipeline\n# Assume 'pipeline' is a defined Pipeline object and 'working_nodes' is a list of Node objects\nexperiment = Experiment().map(pipeline, working_nodes)"
  },
  {
    "source": "NetUnicorn Pipeline Basics",
    "content": "A Pipeline defines a sequence of tasks. Tasks are added using .then(). Example: \nfrom netunicorn.base.pipeline import Pipeline\nfrom netunicorn.library.tasks.basic import SleepTask\npipeline = Pipeline().then(SleepTask(5))"
  },
  {
    "source": "NetUnicorn Node Selection",
    "content": "To get nodes, use client.get_nodes(). You can filter nodes or take a subset. Example: \nall_nodes = client.get_nodes()\n# To use a specific number of available nodes:\nworking_nodes = all_nodes.take(1) # Takes the first available node\n# To filter for a specific node by name:\n# working_nodes = all_nodes.filter(lambda node: node.name == 'snl-server-5').take(1)\nEnsure working_nodes is a list-like structure suitable for prepare_experiment."
  },
  {
    "source": "NetUnicorn Experiment Lifecycle and Naming",
    "content": "Define a unique string for experiment_name, e.g., experiment_name = \"my_sleep_experiment\".\nBefore preparing, you can delete any pre-existing experiment with the same name:\nfrom netunicorn.client.remote import RemoteClient\n# client = RemoteClient(...) # Assume client is initialized\nexperiment_name = \"your_experiment_name_here\" # Define your experiment name\ntry:\n    client.delete_experiment(experiment_name)\nexcept Exception as e:\n    print(f\"Info: Could not delete experiment {experiment_name} (may not exist): {e}\")\n\nThen, prepare, start, and wait for the experiment:\n# Assume 'pipeline' is a defined Pipeline object and 'working_nodes' is a list of Node objects\nclient.prepare_experiment(pipeline, working_nodes, experiment_name)\nprint(f\"Experiment {experiment_name} prepared. Waiting for readiness...\")\n# Robust scripts should poll client.get_experiment_status(experiment_name).status until it's 'READY'.\nclient.start_execution(experiment_name)\nprint(f\"Experiment {experiment_name} started. Waiting for completion...\")\nclient.wait_for_experiment(experiment_name)\nprint(f\"Experiment {experiment_name} finished.\")\nresults = client.get_experiment_status(experiment_name).execution_result\nprint(f\"Results: {results}\")"
  },
  {
    "source": "NetUnicorn SleepTask",
    "content": "The SleepTask makes the node sleep for a specified number of seconds. Example: \nfrom netunicorn.library.tasks.basic import SleepTask\ntask = SleepTask(duration_in_seconds=10) # e.g., SleepTask(10) for 10 seconds."
  },
  {
    "source": "NetUnicorn Full Script Structure Example",
    "content": "A typical NetUnicorn script involves: \n1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). \n2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. \n3. Creating a `RemoteClient` instance. \n4. Creating a `Pipeline` and adding tasks using `.then()`. \n5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). \n6. Defining an `experiment_name` (string). \n7. Deleting any pre-existing experiment with the same name (using try-except). \n8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. \n9. Starting the experiment: `client.start_execution(experiment_name)`. \n10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. \n11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.\nExample snippet for lifecycle:\n```python\n# ... imports, client, pipeline, nodes defined ...\nexperiment_name = \"my_unique_experiment_name\"\ntry:\n    client.delete_experiment(experiment_name)\nexcept Exception as e:\n    print(f\"Info: could not delete {experiment_name}: {e}\")\nclient.prepare_experiment(pipeline, working_nodes, experiment_name)\nclient.start_execution(experiment_name)\nstatus = client.wait_for_experiment(experiment_name)\nprint(f\"Experiment finished with status: {status}\")\nresults = client.get_experiment_status(experiment_name).execution_result\nprint(results)\n```"
  },
  {
    "source": "NetUnicorn BaseClient Methods",
    "content": "The `netunicorn.client.base.BaseClient` provides core methods for interacting with the netunicorn system. Key methods include:\\n- `get_nodes()`: Returns currently available nodes.\\n- `get_experiments()`: Gets information about all experiments for the current user.\\n- `delete_experiment(experiment_name)`: Deletes an experiment to release its name.\\n- `healthcheck()`: Checks if the netunicorn instance is healthy.\\n- `prepare_experiment(experiment, experiment_id)`: Prepares an experiment for execution (compiling, distributing environment).\\n- `start_execution(experiment_id)`: Starts a prepared experiment.\\n- `get_experiment_status(experiment_id)`: Returns the status and results of an experiment.\\n- `cancel_experiment(experiment_id)`: Cancels experiment execution.\\n- `cancel_executors(executors)`: Cancels specific executors.\\n- `get_flag_values(experiment_id, flag_name)`: Gets flag values for an experiment flag.\\n- `set_flag_values(experiment_id, flag_name, flag_values)`: Sets flag values for an experiment flag.\\nThese methods are fundamental for managing experiments, nodes, and system health. (Reference: https://netunicorn.github.io/netunicorn/_autosummary/netunicorn.client.base.BaseClient.html)"
  },
  {
    "source": "NetUnicorn Library: basic.py Tasks",
    "content": "Tasks from `netunicorn.library.tasks.basic`:\\\\n- `DummyTask()`: A simple task whose `run()` method returns `True`. Useful for testing pipeline functionality.\\\\n- `SleepTask(seconds: int)`: Causes the execution to pause for the specified number of `seconds`. Example: `SleepTask(10)` will sleep for 10 seconds."
  },
  {
    "source": "NetUnicorn Library: flags.py Tasks",
    "content": "Tasks from `netunicorn.library.tasks.flags` for interacting with node-specific flags and system information:\\\\n- `SetFlagTask(name: str, value: str)`: Sets a key-value pair (flag) on the node. Can be retrieved later or by other tasks.\\\\n- `GetFlagTask(name: str)`: Retrieves the value of a previously set flag.\\\\n- `GetSerializationFormat()`: Returns the serialization format used by the minion (e.g., 'json', 'pickle').\\\\n- `CheckIPVersion(version: Literal[4, 6], bind_address: Optional[str] = None)`: Checks if the specified IP version (4 or 6) is connectable from the node, optionally trying to bind to a specific address.\\\\n- `GetOwnIP(version: Literal[4, 6])`: Returns the node\\'s own IP address for the specified version.\\\\n- `CheckFreeSpace(path: str)`: Returns the free disk space (in bytes) at the given `path` on the node.\\\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary shell `command` on the node. Returns `Success` with stdout or `Failure` with stderr.\\\\n- `Commands(commands: List[str])`: Executes a list of shell `commands` sequentially. Stops on first failure.\\\\n- `GetKernelVersion()`: Returns the kernel version string of the node.\\\\n- `Reboot(delay_seconds: int = 0)`: Reboots the machine after `delay_seconds`."
  },
  {
    "source": "NetUnicorn Library: tasks_utils.py Functions",
    "content": "Utility functions from `netunicorn.library.tasks.tasks_utils` (primarily for use within other tasks):\\\\n- `subprocess_run(arguments: list[str]) -> Result`: A helper function to run a subprocess with the given `arguments` (a list of strings). It captures stdout and stderr. Returns `Success(stdout_lines)` or `Failure(stderr_lines)`."
  },
  {
    "source": "NetUnicorn Library: capture Tasks",
    "content": "Tasks from `netunicorn.library.tasks.capture` for network traffic capture:\\\\n- `capture.tcpdump.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tcpdump process, saving output to `filepath`. Custom `arguments` can be provided.\\\\n- `capture.tcpdump.StopNamedCapture(name: str)`: Stops a tcpdump process that was started with a specific `name` (referring to the `StartCapture` task name).\\\\n- `capture.tcpdump.StopAllCapture()`: Stops all currently running tcpdump processes initiated by the library on the node.\\\\n- `capture.tshark.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tshark process, saving output to `filepath`. Custom `arguments` can be provided.\\\\n- `capture.tshark.StopNamedCapture(name: str)`: Stops a tshark process started with a specific `name`.\\\\n- `capture.tshark.StopAllCapture()`: Stops all currently running tshark processes initiated by the library on the node."
  },
  {
    "source": "NetUnicorn Library: data_transfer Tasks",
    "content": "Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\\\\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal[\"ookla-speedtest\", \"pcp-speedtest\", \"iperf3\", \"netperf\", \"flent\", \"file\"] = \"file\", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\\\\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task."
  },
  {
    "source": "NetUnicorn Library: letsencrypt Tasks",
    "content": "Tasks from `netunicorn.library.tasks.letsencrypt` for automating Let's Encrypt certificate issuance:\\\\n- `LetsEncryptDNS01Validation(acme_server: str, email: str, domains: List[str], dns_hook: str, dns_unhook: str, key_type: str = \"rsa\")`: Performs DNS-01 validation. Requires providing paths to `dns_hook` and `dns_unhook` scripts compatible with dehydrated.\\\\n- `LetsEncryptHTTP01Validation(acme_server: str, email: str, domains: List[str], key_type: str = \"rsa\")`: Performs HTTP-01 validation. The node must be publicly accessible on port 80.\\\\nHelper functions (usually not called directly in pipelines):\\\\n- `validate_http_01(domain: str, token_name: str, token_data: str)`\\\\n- `validate_dns_01(domain: str, validation_string: str)`"
  },
  {
    "source": "NetUnicorn Library: measurements Tasks (General)",
    "content": "General measurement tasks from `netunicorn.library.tasks.measurements`:\\\\n- `measurements.flent.StartServer()`: Starts a flent (Flexible Network Tester) server process.\\\\n- `measurements.flent.StopServer(start_server_task_name: str)`: Stops a flent server started by a previous task named `start_server_task_name`.\\\\n- `measurements.flent.RunFlentTest(server_address: str, test_name: str, plot_filename: Optional[str] = None, test_parameters: Optional[dict] = None)`: Runs a flent test against `server_address` using `test_name` (e.g., 'tcp_good'). Optionally saves a plot and passes extra parameters.\\\\n- `measurements.iperf3.Iperf3ServerStart(flags: Optional[list[str]] = None)`: Starts an iperf3 server with optional `flags`.\\\\n- `measurements.iperf3.Iperf3ServerStop(server_task_name: str)`: Stops an iperf3 server started by `server_task_name`.\\\\n- `measurements.iperf3.Iperf3Client(server_ip: str, flags: Optional[list[str]] = None)`: Runs an iperf3 client against `server_ip` with optional `flags`.\\\\n- `measurements.ndt.NDT7SpeedTest(server: Optional[str] = None)`: Performs an NDT7 speed test, optionally specifying a server. Also available: `NDT7SpeedTestLinuxAMD64`, `NDT7SpeedTestLinuxARM64`. `_NDTSpeedTestImplementation` is a base class.\\\\n- `measurements.ookla_speedtest.OoklaSpeedtest(server_selection_task_name: str = \"\", source_ip: str = \"\", timeout: int = 100)`: Runs an Ookla Speedtest CLI test. Can take a server ID from a `ServerSelection` task result (via `server_selection_task_name`) or ping a `source_ip` to select a server. If neither, selects automatically.\\\\n- `measurements.ookla_speedtest.ServerSelection(callback: Callable[[list[ServerInfo]], str])`: Lists available Ookla servers and allows a user-provided `callback` function to choose one by returning its ID. `ServerInfo` is a dataclass with id, host, port, name, location, country.\\\\n- `measurements.ookla_speedtest.OoklaSpeedtestAnalysis(speedtest_task_name: str)`: Analyzes the JSON results from a previous `OoklaSpeedtest` task (identified by `speedtest_task_name`). It classifies latency (good, ok, strange, problem) and throughput (low, ok, good, excellent) and returns a summary dictionary.\\\\n- `measurements.ping.Ping(host: str, count: Optional[int] = None, interval: Optional[float] = None, timeout: Optional[float] = None, interface: Optional[str] = None)`: Performs an ICMP ping to `host` with options for count, interval, timeout, and source interface."
  },
  {
    "source": "NetUnicorn Library: measurements Tasks (Specialized)",
    "content": "Specialized measurement tasks from submodules of `netunicorn.library.tasks.measurements`:\\\\n- `measurements.alexa.alexa.AlexaWebsitesTask(num_of_websites: int)`: Performs network measurements (curl, dig, traceroute, ping) to the top `num_of_websites` from the Alexa Top 1 Million list.\\\\n- `measurements.cloudflare.speedtest.CloudflareSpeedTest(count: int = 3, warmup_bytes: int = 100000)`: Runs a speed test using Cloudflare's network, performing `count` tests after a warmup phase. (Dispatcher for `CloudflareSpeedTestLinuxImplementation`)"
  },
  {
    "source": "NetUnicorn Library: network_attacks Tasks",
    "content": "Tasks from `netunicorn.library.tasks.network_attacks` and its submodules, for simulating various network attacks. Use responsibly and only on authorized systems.\\\\n- `network_attacks.arp.ArpSpoof(target_ip: str, spoof_ip: str, interface: str = \"eth0\", duration_seconds: int = 60)`: Performs ARP spoofing between `target_ip` and `spoof_ip` on the given `interface` for `duration_seconds`.\\\\n- `network_attacks.cve202141773.CVE202141773(target: str, path: str = \"/cgi-bin/.%2e/%2e%2e/%2e%2e/etc/passwd\")`: Attempts to exploit Apache path traversal (CVE-2021-41773) against `target` using the specified `path`.\\\\n- `network_attacks.ftp.BruteForceFTP(target: str, username: str, wordlist: list[str])`: Attempts to brute-force FTP login credentials.\\\\n- `network_attacks.heartbleed.Heartbleed(host: str, port: int = 443, count: int = 1, length: int = 0xFFFF, tls_version: Literal[\"tls10\", \"tls11\", \"tls12\"] = \"tls11\", starttls_proto: Optional[str] = None, data: Optional[str] = None)`: Tests for the Heartbleed vulnerability (CVE-2014-0160).\\\\n- `network_attacks.heartbleed2.Heartbleed(IPaddress: str, port: int, starttls: bool = False, debug: bool = False)`: An alternative implementation for testing Heartbleed.\\\\n- `network_attacks.icmp.ICMPRedirection(target: str, old_gw: str, new_gw: str)`: Sends ICMP redirect packets to `target`, instructing it to use `new_gw` instead of `old_gw`.\\\\n- `network_attacks.land.LANDAttack(target_ip: str, source_port: int = 1001, destination_port: int = 80)`: Performs a LAND attack by sending a packet with the same source and destination IP/port to `target_ip`.\\\\n- `network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a JNDI lookup at `cc_address`.\\\\n- `network_attacks.loris.SlowLoris(host: str, port: int = 80, sockets: int = 150, https: bool = False, sleeptime: int = 15, slowloris_iterations: int = 100)`: Performs a Slowloris denial-of-service attack.\\\\n- `network_attacks.loris.SMBLoris(host: str, starting_source_port: int = 10000, number_of_ports: int = 1000)`: Performs a resource exhaustion attack against SMB (port 445).\\\\n- `network_attacks.mac.MACFlooder(iface: str = \"eth0\", count: int = 1000)`: Floods the network with Ethernet frames with random MAC addresses to overwhelm switch CAM tables.\\\\n- `network_attacks.mail.FakeMail(host: str, port: int, sender: str, recipient: str, subject: str, body: str)`: Sends an email using raw SMTP commands (potentially for spoofing, use with caution).\\\\n- `network_attacks.ssh.BruteForceSSH(targetIP: str, wordlist: list[str], port: int = 22, user: str = \"root\")`: Attempts to brute-force SSH login credentials using paramiko."
  },
  {
    "source": "NetUnicorn Library: preprocessing Tasks",
    "content": "Tasks from `netunicorn.library.tasks.preprocessing` for processing captured network data (e.g., pcap files) on the node:\\\\n- `preprocessing.scapy.Get5Tuples(filename: str)`: Reads a pcap file (`filename`) and extracts 5-tuples (src_ip, dst_ip, src_port, dst_port, proto) for TCP/UDP packets.\\\\n- `preprocessing.scapy.GetDNSQueries(filename: str)`: Extracts DNS query names from a pcap file.\\\\n- `preprocessing.scapy.GetHTTPHostHeaders(filename: str)`: Attempts to extract HTTP Host headers from raw packet data in a pcap file.\\\\n- `preprocessing.scapy.GetICMPRequests(filename: str)`: Extracts ICMP echo request packets from a pcap file.\\\\n- `preprocessing.scapy.GetUniqueARPMAC(filename: str)`: Extracts unique source MAC addresses from ARP packets in a pcap file.\\\\n- `preprocessing.tshark.TsharkCommand(command: list[str])`: Executes a given `tshark` command (provided as a list of strings) on the node.\\\\n- `preprocessing.zeek.ZeekPCAPAnalysis(pcap_filename: str, flags: Optional[list[str]] = None)`: Analyzes the `pcap_filename` using Zeek with optional `flags`. This is a TaskDispatcher for `ZeekPCAPAnalysisLinuxImplementation` which includes requirements to install Zeek from a Debian repository."
  },
  {
    "source": "NetUnicorn Library: qoe_youtube Tasks",
    "content": "Tasks from `netunicorn.library.tasks.qoe_youtube` for Quality of Experience (QoE) monitoring of YouTube videos. This system involves a collection server and a video watching task.\\\\n- `qoe_youtube.StartQoECollectionServer(data_folder: str = \".\", interface: str = \"0.0.0.0\", port: int = 34543)`: Starts a FastAPI-based server (`qoe_collector.py`) on the node to receive QoE data. Data is stored in `data_folder`. The server listens on `interface:port`. Returns `(success_message_with_pid, process_id)` or `Failure`. (Dispatcher for Linux implementation with uvicorn requirements).\\\\n- `qoe_youtube.StopQoECollectionServer(start_task_name: str)`: Stops the QoE collection server that was started by the task named `start_task_name`.\\\\n- `qoe_youtube.WatchYouTubeVideo(video_url: str, duration: Optional[int] = None, quality: Optional[int] = None, qoe_server_address: str = \"localhost\", qoe_server_port: int = 34543, report_time: int = 250)`: Watches a YouTube `video_url` using Selenium and two Chrome extensions (an adblocker and a custom QoE stats collector). It sends QoE metrics (player state, quality changes, periodic stats) to the specified `qoe_server_address:qoe_server_port`. `duration` specifies watch time (None for full video). `quality` can request a specific resolution. `report_time` is the interval for sending periodic stats (in ms). (Dispatcher for Linux implementation with extensive Selenium/Chrome/extension setup requirements). The underlying watcher logic is in `watcher.py`."
  },
  {
    "source": "NetUnicorn Library: upload Tasks",
    "content": "Tasks from `netunicorn.library.tasks.upload` for uploading files from the node to various destinations:\\\\n- `upload.fileio.UploadToFileIO(filepath: str, expires: str = \"14d\")`: Uploads the local file at `filepath` to `file.io`, a temporary file sharing service. The `expires` parameter (e.g., \"1d\", \"1w\") controls expiration. (Uses curl).\\\\n- `upload.ftp.UploadToFTP(local_filepath: str, ftp_url: str, username: str, password: str, destination_dir: str = \"/\", timeout: int = 30)`: Uploads `local_filepath` to an FTP server at `ftp_url` using `username` and `password`, into `destination_dir`.\\\\n- `upload.ftp.RetrieveFromFTP(ftp_remote_filepath: str, ftp_url: str, username: str, password: str, local_dir: str = \"./\", timeout: int = 30)`: Downloads `ftp_remote_filepath` from an FTP server to the `local_dir`.\\\\n- `upload.googlecloud.UploadToGoogleCloudStorage(local_filepath: str, bucket: str, target_filepath: str = \"\", auth_token: Optional[str] = None)`: Uploads `local_filepath` to the specified Google Cloud Storage `bucket`, optionally at `target_filepath` within the bucket. An `auth_token` can be provided for private buckets. (Uses curl).\\\\n- `upload.webdav.UploadToWebDav(filepaths: Set[str], endpoint: str, username: Optional[str] = None, password: Optional[str] = None, authentication: Literal[\"basic\"] = \"basic\")`: Uploads a set of local `filepaths` to a WebDAV `endpoint`. Uploads into a subdirectory named after the `NETUNICORN_EXECUTOR_ID`. Supports basic authentication. (Uses curl)."
  },
  {
    "source": "NetUnicorn Library: utils Tasks",
    "content": "General utility tasks from `netunicorn.library.tasks.utils`:\\\\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a \"knock\") to the specified `ip` and `port`. Does not return success/failure of the knock itself, always returns 0.\\\\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) which will sleep for a random duration between `seconds_min` and `seconds_max` (inclusive)."
  },
  {
    "source": "NetUnicorn Library: video_watchers Tasks",
    "content": "Selenium-based tasks from `netunicorn.library.tasks.video_watchers` for watching online videos. These are simpler watchers compared to the `qoe_youtube` one and do not involve QoE metric collection extensions by default.\\\\n- `video_watchers.twitch_watcher.WatchTwitchStream(video_url: str, duration: Optional[int] = 10, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Twitch stream at `video_url` for `duration` seconds. Uses a headless Chrome/Chromium environment via Xvfb.\\\\n- `video_watchers.vimeo_watcher.WatchVimeoVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Vimeo video at `video_url`. If `duration` is provided, watches for that many seconds. If `duration` is None, it attempts to watch until the video ends by checking player state.\\\\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a YouTube video at `video_url`. Similar to the Vimeo watcher, it can watch for a fixed `duration` or attempt to watch until the end by checking player state via JavaScript. Uses `YouTubeIFrameStatus` enum for player states.\\\\nAll these watchers are TaskDispatchers that delegate to Linux-specific implementations which handle Selenium and Xvfb setup (typically requiring `chromium`, `chromium-driver`, `xvfb`, `selenium`). The default `chrome_location` is often `/usr/bin/chromium`."
  },
  {
    "source": "NetUnicorn Library: Example Pipelines (measurements)",
    "content": "The `netunicorn.library.pipelines.measurements` module provides example pre-defined pipelines:\\\\n- `pipelines.measurements.ookla_speedtest.simple_speedtest_pipeline() -> Pipeline`: Defines a pipeline that runs `OoklaSpeedtest` and then `OoklaSpeedtestAnalysis` on its results. A good example of a simple measurement and analysis sequence.\\\\n- `pipelines.measurements.netflex_pipeline.netflex_ookla_full_loop_pipeline() -> Pipeline`: Runs `OoklaSpeedtest`, then uses `SendData` to send results to an endpoint defined by the `RAG_ENDPOINT` environment variable, and then uses `FetchData` to retrieve data from the same endpoint. This suggests an integration pattern with an external RAG/analysis system.\\\\n- `pipelines.measurements.netflex_pipeline.netflex_mlab_full_loop_pipeline() -> Pipeline`: Similar to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type \"mlab-speedtest\") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not explicitly imported in this file, relying on its availability.\\\\nThese example pipelines demonstrate how to chain measurement tasks, data transfer tasks, and analysis tasks, and show potential integration patterns with external systems via environment variables like `RAG_ENDPOINT`."
  }
]
