[
  {
    "source": "NetUnicorn Basic Client Usage",
    "content": "To interact with NetUnicorn, you first need to create a RemoteClient instance. Example: \nfrom netunicorn.client.remote import RemoteClient\nclient = RemoteClient(endpoint='your_endpoint', login='your_login', password='your_password')\nclient.healthcheck() can be used to verify the connection."
  },
  {
    "source": "NetUnicorn Experiment Object and Environment Definition",
    "content": "An Experiment in NetUnicorn is defined by creating an `Experiment` object and then mapping a `Pipeline` to a set of nodes. Example: \nfrom netunicorn.base.experiment import Experiment\nfrom netunicorn.base.pipeline import Pipeline\n# Assume 'pipeline' is a defined Pipeline object and 'working_nodes' is a list of Node objects\nexperiment = Experiment()\nexperiment.map(pipeline, working_nodes) \nSetting `experiment.environment_definition` (e.g., to `ShellExecution`) is often not required if tasks are self-contained or use standard library functionalities, as a default environment is typically used. Only set it explicitly if specific environment behavior (like a Docker image or a plain shell for raw commands) is needed. If setting, ensure the class (e.g., `from netunicorn.base.environment_definitions import ShellExecution`) is imported and set on the experiment object, often before `client.prepare_experiment(...)`."
  },
  {
    "source": "NetUnicorn Pipeline Basics and Chaining Tasks",
    "content": "A Pipeline defines a sequence of tasks. Tasks are added using `.then()`. \nExample: `pipeline = Pipeline().then(TaskOne()).then(TaskTwo())`.\nEnsure all task classes are imported correctly based on their specific modules within `netunicorn.library.tasks` or other locations."
  },
  {
    "source": "NetUnicorn Node Selection",
    "content": "To get nodes, use `client.get_nodes()`. This returns a `NodePool` object. You can filter nodes or take a subset. Example: \nnode_pool = client.get_nodes()\n# To use a specific number of available nodes:\nworking_nodes = node_pool.take(1) # Takes the first available node\n# To filter for a specific node by name:\n# working_nodes = node_pool.filter(lambda node: node.name == 'specific-node-name').take(1)\nAlways check if `working_nodes` is empty before proceeding, as an experiment cannot run on zero nodes."
  },
  {
    "source": "NetUnicorn Environment Definitions",
    "content": "Experiments MAY require an `environment_definition` if the default execution environment is not suitable. This is assigned to `experiment.environment_definition`. \n- `ShellExecution`: Use for tasks that are simple shell commands (like `ExecuteShellCommand`) or Python tasks requiring a basic shell. \n  Import: `from netunicorn.base.environment_definitions import ShellExecution`\n  Usage: `experiment.environment_definition = ShellExecution()`\n- `DockerImage`: For tasks needing a specific Docker container.\n  Import: `from netunicorn.base.environment_definitions import DockerImage`\n  Usage: `experiment.environment_definition = DockerImage(image='your_docker_image:latest')`\nMany library tasks (e.g., `SleepTask`) run correctly without an explicitly set `environment_definition`. If set, it must be assigned to the `Experiment` object, typically before `client.prepare_experiment(...)`."
  },
  {
    "source": "NetUnicorn Experiment Lifecycle, Naming, and Preparation",
    "content": "Define an `experiment_name` as a string. This can be static or dynamically generated for uniqueness (e.g., using `time.strftime`). \nExample for unique name: `experiment_name = f\"my_exp_{time.strftime('%Y%m%d%H%M%S')}\"`\nBefore preparing, it's good practice to attempt to delete any pre-existing experiment with the same name:\n```python\nfrom netunicorn.client.remote import RemoteClientException # Ensure import\ntry:\n    client.delete_experiment(experiment_name)\nexcept RemoteClientException:\n    pass # Common to ignore if experiment simply doesn't exist\n```\nThen, prepare the experiment: `client.prepare_experiment(experiment, experiment_name)` where `experiment` is your `Experiment` object. Import `ExperimentStatus` from `netunicorn.base.experiment` for polling."
  },
  {
    "source": "NetUnicorn Full Script Structure Example (Generic Task Flow)",
    "content": "A typical NetUnicorn script involves the following general flow. Replace TaskName with the specific task you want to run, and ensure its correct import and any specific environment definition needs are met based on other documentation entries.\n\n```python\n# 1. Standard Imports\nimport os\nimport time\nfrom pprint import pprint\n\n# 2. NetUnicorn Core Imports\nfrom netunicorn.client.remote import RemoteClient, RemoteClientException\nfrom netunicorn.base.pipeline import Pipeline\nfrom netunicorn.base.experiment import Experiment, ExperimentStatus\nfrom netunicorn.base.environment_definitions import ShellExecution # Example, only if needed\n\n# 3. NetUnicorn Task Imports (Replace with actual task)\n# from netunicorn.library.tasks.basic import SleepTask # Example: SleepTask\n# from netunicorn.library.tasks.flags import ExecuteShellCommand # Example: ExecuteShellCommand\n# from netunicorn.library.tasks import SomeOtherTask # Placeholder for your specific task\n\n# 4. Result Handling Imports (if using returns.Result)\nfrom returns.pipeline import is_successful\nfrom returns.result import Result\n\n# 5. Credentials (Will be injected or defined in the script)\n# NETUNICORN_ENDPOINT = \"your_endpoint\"\n# NETUNICORN_LOGIN = \"your_login\"\n# NETUNICORN_PASSWORD = \"your_password\"\n\n# 6. Client Initialization\n# client = RemoteClient(endpoint=NETUNICORN_ENDPOINT, login=NETUNICORN_LOGIN, password=NETUNICORN_PASSWORD)\n# print(f\"Client Healthcheck: {client.healthcheck()}\")\n\n# 7. Pipeline Creation (Customize with your task)\n# pipeline = Pipeline().then(TaskName(...params...)) # e.g., SleepTask(5) or ExecuteShellCommand('echo hello')\n\n# 8. Node Selection\n# node_pool = client.get_nodes()\n# if not node_pool:\n#     print(\"No nodes available, exiting.\")\n#     exit()\n# working_nodes = node_pool.take(1)\n# if not working_nodes:\n#     print(\"Failed to take any nodes from pool, exiting.\")\n#     exit()\n# print(f\"Selected working nodes: {working_nodes}\")\n\n# 9. Experiment Object Creation & Mapping\n# experiment = Experiment().map(pipeline, working_nodes)\n\n# 10. Environment Definition (If required by the task, e.g., ShellTask)\n# if TaskName requires ShellExecution:\n#     experiment.environment_definition = ShellExecution()\n\n# 11. Experiment Naming (Make it unique)\n# experiment_name = f\"my_task_example_{time.strftime('%Y%m%d%H%M%S')}\"\n# print(f\"Using experiment name: {experiment_name}\")\n\n# 12. Delete Old Experiment (Good practice)\n# try:\n#     client.delete_experiment(experiment_name)\n#     print(f\"Successfully deleted pre-existing experiment: {experiment_name}\")\n# except RemoteClientException:\n#     print(f\"Info: Experiment '{experiment_name}' not found or couldn't be deleted.\")\n\n# 13. Prepare Experiment\n# client.prepare_experiment(experiment, experiment_name)\n# print(f\"Preparing experiment: {experiment_name}\")\n\n# 14. Poll for READY status\n# print(f\"Waiting for experiment {experiment_name} to be READY...\")\n# while True:\n#     status_info = client.get_experiment_status(experiment_name)\n#     print(f\"Current status of {experiment_name}: {status_info.status}\")\n#     if status_info.status == ExperimentStatus.READY:\n#         print(f\"Experiment {experiment_name} is READY.\")\n#         break\n#     elif status_info.status in {ExperimentStatus.FINISHED, ExperimentStatus.ERROR}:\n#         print(f\"Experiment {experiment_name} reached terminal state {status_info.status} before READY. Error: {status_info.error}\")\n#         exit()\n#     time.sleep(5) # Adjust sleep time as needed\n\n# 15. Start Execution\n# client.start_execution(experiment_name)\n# print(f\"Starting execution of {experiment_name}\")\n\n# 16. Poll for Completion (until not RUNNING)\n# print(f\"Waiting for experiment {experiment_name} to complete...\")\n# while True:\n#     status_info = client.get_experiment_status(experiment_name)\n#     print(f\"Current status of {experiment_name}: {status_info.status}\")\n#     if status_info.status != ExperimentStatus.RUNNING:\n#         print(f\"Experiment {experiment_name} is no longer RUNNING. Final status: {status_info.status}\")\n#         break\n#     time.sleep(10) # Adjust sleep time as needed\n\n# 17. Process Results\n# final_status_info = client.get_experiment_status(experiment_name)\n# print(f\"Final experiment status: {final_status_info.status}\")\n# if final_status_info.status == ExperimentStatus.FINISHED and final_status_info.execution_result:\n#     print(\"Experiment Finished Successfully. Processing results:\")\n#     for report in final_status_info.execution_result: # execution_result is a list of reports\n#         print(f\"--- Report for Node: {report.node.name} ---\")\n#         print(f\"  Error (if any): {report.error}\")\n#         actual_result_value, log_list = report.result # Unpack the tuple\n#         print(f\"  Actual Result Type: {type(actual_result_value)}\")\n#         if isinstance(actual_result_value, Result): # Check if it's a returns.Result object\n#             processed_value = actual_result_value.unwrap() if is_successful(actual_result_value) else actual_result_value.failure()\n#             print(f\"  Processed Result (from returns.Result):\")\n#             pprint(processed_value)\n#         else:\n#             print(f\"  Result (raw):\")\n#             pprint(actual_result_value)\n#         print(f\"  Logs:\")\n#         if log_list:\n#             for log_entry in log_list:\n#                 print(f\"    {log_entry.strip()}\")\n#         else:\n#             print(\"    (No logs reported for this task)\")\n#         print(\"--- End Report ---\")\n# elif final_status_info.error:\n#     print(f\"Experiment error details from final_status_info: {final_status_info.error}\")\n# else:\n#     print(f\"Experiment status is {final_status_info.status} but no execution results or other issue.\")\n\n# print(f\"Script for {experiment_name} concluded.\")\n```\nThis structure provides a comprehensive guide. The LLM should fill in the commented-out sections using the specific task details and the user's prompt."
  },
  {
    "source": "NetUnicorn BaseClient Methods",
    "content": "The `netunicorn.client.base.BaseClient` provides core methods. Key methods include:\n- `get_nodes()`: Returns currently available nodes as a `NodePool` object (from `netunicorn.base.nodes`).\n- `delete_experiment(experiment_name: str)`: Deletes an experiment. Raises `RemoteClientException` if experiment doesn't exist or other server-side issues occur.\n- `healthcheck()`: Checks server health.\n- `prepare_experiment(experiment: Experiment, experiment_id: str)`: Prepares an `Experiment` object for execution under the given `experiment_id` string.\n- `start_execution(experiment_id: str)`: Starts a prepared experiment.\n- `get_experiment_status(experiment_id: str)`: Returns `ExperimentExecutionInformation` (from `netunicorn.base.experiment`) which includes status and results. This method is used for polling the experiment's progress."
  },
  {
    "source": "NetUnicorn Library Task: SleepTask",
    "content": "The `SleepTask` pauses execution on a node for a specified number of seconds. It is useful for introducing delays in a pipeline.\n**Import:**\n`from netunicorn.library.tasks.basic import SleepTask`\n**Usage:**\nIn a pipeline, add it like so: `pipeline.then(SleepTask(duration_in_seconds=10))` or simply `pipeline.then(SleepTask(10))`.\n**Considerations:**\n- This task generally does not require a specific `experiment.environment_definition` to be set, as it's a basic Python operation."
  },
  {
    "source": "NetUnicorn Library Task: ShellCommand",
    "content": "The `ShellCommand` task allows you to run arbitrary shell commands on the target node.\n**Import:**\n`from netunicorn.library.tasks.basic import ShellCommand`\n**Usage:**\nIn a pipeline: `pipeline.then(ShellCommand(command=['echo', 'Hello from NetUnicorn Node']))` or `pipeline.then(ShellCommand(command='echo \\\"Legacy Mode Example\\\"'))`. Prefer list format.\n**Considerations:**\n- This task **requires** the experiment's `environment_definition` to be set to `ShellExecution`.\n- Import `ShellExecution` with: `from netunicorn.base.environment_definitions import ShellExecution`\n- Set it on the experiment object: `experiment.environment_definition = ShellExecution()` (typically before `client.prepare_experiment(...)`)."
  },
  {
    "source": "NetUnicorn Library: DummyTask (from basic.py)",
    "content": "The `DummyTask` is a simple task primarily for testing purposes. Its `run()` method typically just returns `True`.\n**Import:** `from netunicorn.library.tasks.basic import DummyTask`\n**Usage:** `pipeline.then(DummyTask())`"
  },
  {
    "source": "NetUnicorn Library: UploadToFileIO (from upload.fileio)",
    "content": "The `UploadToFileIO` task uploads a local file (from the node's filesystem) to the file.io service.\n**Import:** `from netunicorn.library.tasks.upload.fileio import UploadToFileIO`\n**Usage:** `pipeline.then(UploadToFileIO(filepath=\"my_local_file.txt\", expires=\"1d\"))`\n**Considerations:**\n- The `filepath` is relative to the execution directory on the node.\n- `expires` is optional (default is \"14d\") and defines how long the file remains available on file.io (e.g., \"1d\" for 1 day, \"2h\" for 2 hours)."
  },
  {
    "source": "NetUnicorn Library: tasks_utils.py Functions",
    "content": "Utility functions from `netunicorn.library.tasks.tasks_utils` (primarily for use within other tasks):\n- `subprocess_run(arguments: list[str]) -> Result`: A helper function to run a subprocess with the given `arguments` (a list of strings). It captures stdout and stderr. Returns `Success(stdout_lines)` or `Failure(stderr_lines)`."
  },
  {
    "source": "NetUnicorn Library: capture Tasks",
    "content": "Tasks from `netunicorn.library.tasks.capture` for network traffic capture:\n- `capture.tcpdump.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tcpdump process, saving output to `filepath`. Custom `arguments` can be provided.\n- `capture.tcpdump.StopNamedCapture(name: str)`: Stops a tcpdump process that was started with a specific `name` (referring to the `StartCapture` task name).\n- `capture.tcpdump.StopAllCapture()`: Stops all currently running tcpdump processes initiated by the library on the node.\n- `capture.tshark.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tshark process, saving output to `filepath`. Custom `arguments` can be provided.\n- `capture.tshark.StopNamedCapture(name: str)`: Stops a tshark process started with a specific `name`.\n- `capture.tshark.StopAllCapture()`: Stops all currently running tshark processes initiated by the library on the node."
  },
  {
    "source": "NetUnicorn Library: data_transfer Tasks",
    "content": "Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal[\\\"ookla-speedtest\\\", \\\"pcp-speedtest\\\", \\\"iperf3\\\", \\\"netperf\\\", \\\"flent\\\", \\\"file\\\"] = \\\"file\\\", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task."
  },
  {
    "source": "NetUnicorn Library: letsencrypt Tasks",
    "content": "Tasks from `netunicorn.library.tasks.letsencrypt` for automating Let's Encrypt certificate issuance:\n- `LetsEncryptDNS01Validation(acme_server: str, email: str, domains: List[str], dns_hook: str, dns_unhook: str, key_type: str = \\\"rsa\\\")`: Performs DNS-01 validation. Requires providing paths to `dns_hook` and `dns_unhook` scripts compatible with dehydrated.\n- `LetsEncryptHTTP01Validation(acme_server: str, email: str, domains: List[str], key_type: str = \\\"rsa\\\")`: Performs HTTP-01 validation. The node must be publicly accessible on port 80."
  },
  {
    "source": "NetUnicorn Library: measurements Tasks (General)",
    "content": "General measurement tasks from `netunicorn.library.tasks.measurements`:\n- `measurements.flent.StartServer()`: Starts a flent (Flexible Network Tester) server process.\n- `measurements.flent.StopServer(start_server_task_name: str)`: Stops a flent server started by a previous task named `start_server_task_name`.\n- `measurements.flent.RunFlentTest(server_address: str, test_name: str, plot_filename: Optional[str] = None, test_parameters: Optional[dict] = None)`: Runs a flent test against `server_address` using `test_name` (e.g., 'tcp_good'). Optionally saves a plot and passes extra parameters.\n- `measurements.iperf3.Iperf3ServerStart(flags: Optional[list[str]] = None)`: Starts an iperf3 server with optional `flags`.\n- `measurements.iperf3.Iperf3ServerStop(server_task_name: str)`: Stops an iperf3 server started by `server_task_name`.\n- `measurements.iperf3.Iperf3Client(server_ip: str, flags: Optional[list[str]] = None)`: Runs an iperf3 client against `server_ip` with optional `flags`.\n- `measurements.ndt.NDT7SpeedTest(server: Optional[str] = None)`: Performs an NDT7 speed test, optionally specifying a server.\n- `measurements.ookla_speedtest.OoklaSpeedtest(...)`: Runs an Ookla Speedtest CLI test. (See specific entry for more details).\n- `measurements.ookla_speedtest.ServerSelection(...)`: Lists available Ookla servers. (See specific entry).\n- `measurements.ookla_speedtest.OoklaSpeedtestAnalysis(...)`: Analyzes Ookla results. (See specific entry).\n- `measurements.ping.Ping(host: str, count: Optional[int] = None, ...)`: Performs ICMP ping."
  },
  {
    "source": "NetUnicorn Library Task: OoklaSpeedtest",
    "content": "The `OoklaSpeedtest` task from `netunicorn.library.tasks.measurements.ookla_speedtest` runs an Ookla Speedtest CLI test on the node.\n**Import:**\n`from netunicorn.library.tasks.measurements.ookla_speedtest import OoklaSpeedtest`\n**Usage:**\n`pipeline.then(OoklaSpeedtest(server_selection_task_name=\"name_of_server_selection_task\", source_ip=\"optional_source_ip_for_selection\", timeout=100))`\nAlternatively, can be run without `server_selection_task_name` or `source_ip` to let Ookla CLI auto-select a server.\n**Considerations:**\n- May require the Ookla Speedtest CLI to be installed on the execution nodes or provided via a Docker environment.\n- Often used in conjunction with `ServerSelection` and `OoklaSpeedtestAnalysis` tasks."
  },
  {
    "source": "NetUnicorn Library Task: ServerSelection (Ookla)",
    "content": "The `ServerSelection` task from `netunicorn.library.tasks.measurements.ookla_speedtest` lists available Ookla Speedtest servers and allows a callback function to choose one.\n**Import:**\n`from netunicorn.library.tasks.measurements.ookla_speedtest import ServerSelection, ServerInfo`\n**Usage:**\n```python\n# Define your callback function\n# def my_server_selector(servers: list[ServerInfo]) -> str:\n#     # logic to select a server and return its ID\n#     if servers:\n#         return servers[0].id # Example: select the first server\n#     return \"\" # Return empty string or raise error if no suitable server\n#\n# pipeline.then(ServerSelection(callback=my_server_selector).set_name(\"select_ookla_server\"))\n```\n**Considerations:**\n- The callback function receives a list of `ServerInfo` objects and should return the string ID of the chosen server.\n- The result of this task (the server ID) is often consumed by a subsequent `OoklaSpeedtest` task by referencing this task's name."
  },
  {
    "source": "NetUnicorn Library Task: OoklaSpeedtestAnalysis",
    "content": "The `OoklaSpeedtestAnalysis` task from `netunicorn.library.tasks.measurements.ookla_speedtest` analyzes the JSON output from a previous `OoklaSpeedtest` task.\n**Import:**\n`from netunicorn.library.tasks.measurements.ookla_speedtest import OoklaSpeedtestAnalysis`\n**Usage:**\n`pipeline.then(OoklaSpeedtestAnalysis(speedtest_task_name=\"name_of_ookla_speedtest_task\"))`\n**Considerations:**\n- `speedtest_task_name` must match the name given to the `OoklaSpeedtest` task in the pipeline (e.g., using `.set_name(\"run_ookla_test\")`).\n- It classifies latency and throughput and returns a summary dictionary."
  },
  {
    "source": "NetUnicorn Library: measurements Tasks (Specialized)",
    "content": "Specialized measurement tasks from submodules of `netunicorn.library.tasks.measurements`:\n- `measurements.alexa.alexa.AlexaWebsitesTask(num_of_websites: int)`: Performs network measurements (curl, dig, traceroute, ping) to the top `num_of_websites` from the Alexa Top 1 Million list.\n- `measurements.cloudflare.speedtest.CloudflareSpeedTest(count: int = 3, warmup_bytes: int = 100000)`: Runs a speed test using Cloudflare's network, performing `count` tests after a warmup phase. (Dispatcher for `CloudflareSpeedTestLinuxImplementation`)"
  },
  {
    "source": "NetUnicorn Library: network_attacks Tasks",
    "content": "Tasks from `netunicorn.library.tasks.network_attacks` and its submodules, for simulating various network attacks. Use responsibly and only on authorized systems. Examples:\n- `network_attacks.arp.ArpSpoof(...)`\n- `network_attacks.cve202141773.CVE202141773(...)`\n- `network_attacks.ftp.BruteForceFTP(...)`\n(Refer to specific modules for import paths and parameters)."
  },
  {
    "source": "NetUnicorn Library: preprocessing Tasks",
    "content": "Tasks from `netunicorn.library.tasks.preprocessing` for processing captured network data (e.g., pcap files) on the node. Examples:\n- `preprocessing.scapy.Get5Tuples(filename: str)`\n- `preprocessing.scapy.GetDNSQueries(filename: str)`\n- `preprocessing.tshark.TsharkCommand(command: list[str])`\n- `preprocessing.zeek.ZeekPCAPAnalysis(...)`\n(Refer to specific modules for import paths and parameters)."
  },
  {
    "source": "NetUnicorn Library: qoe_youtube Tasks",
    "content": "Tasks from `netunicorn.library.tasks.qoe_youtube` for Quality of Experience (QoE) monitoring of YouTube videos. Involves a collection server and a video watching task.\n- `qoe_youtube.StartQoECollectionServer(...)`\n- `qoe_youtube.StopQoECollectionServer(...)`\n- `qoe_youtube.WatchYouTubeVideo(...)`\n(These are complex tasks, often dispatchers for OS-specific implementations with significant dependencies like Selenium/Chrome. Refer to the module for details.)"
  },
  {
    "source": "NetUnicorn Library: upload Tasks (General Info)",
    "content": "General information about upload tasks. Tasks in `netunicorn.library.tasks.upload` facilitate uploading files from nodes. See specific task entries (like `UploadToFileIO`) for details.\nOther tasks include (refer to their respective modules for imports and usage):\n- `upload.ftp.UploadToFTP(...)`\n- `upload.googlecloud.UploadToGoogleCloudStorage(...)`\n- `upload.webdav.UploadToWebDav(...)`"
  },
  {
    "source": "NetUnicorn Library: utils Tasks",
    "content": "General utility tasks from `netunicorn.library.tasks.utils`:\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a \\\"knock\\\").\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) with a random duration."
  },
  {
    "source": "NetUnicorn Library: video_watchers Tasks",
    "content": "Selenium-based tasks from `netunicorn.library.tasks.video_watchers` for watching online videos (Twitch, Vimeo, YouTube). These are typically TaskDispatchers for OS-specific implementations with Selenium/Xvfb dependencies.\n- `video_watchers.twitch_watcher.WatchTwitchStream(...)`\n- `video_watchers.vimeo_watcher.WatchVimeoVideo(...)`\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(...)`\n(Refer to specific modules for import paths and parameters)."
  },
  {
    "source": "NetUnicorn Library: Example Pipelines (measurements)",
    "content": "The `netunicorn.library.pipelines.measurements` module provides example pre-defined pipelines such as `simple_speedtest_pipeline()` or `netflex_ookla_full_loop_pipeline()`. These demonstrate how to chain measurement, data transfer, and analysis tasks."
  }
]