# NetUnicorn RAG Evaluation Report
Generated: 2025-05-26T19:47:53.588522

## 1. Basic Task
Prompt: Generate a NetUnicorn script that selects two available nodes and makes each of them sleep for 15 seconds. Then, print the results.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a NetUnicorn script that selects two available nodes and makes each of them sleep for 15 seconds. Then, print the results."

Chunk 1 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 2 (source: NetUnicorn Library: utils Tasks): 

```
General utility tasks from `netunicorn.library.tasks.utils`:\\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a "knock") to the specified `ip` and `port`. Does not return success/failure of the knock itself, always returns 0.\\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) which will sleep for a random duration between `seconds_min` and `seconds_max` (inclusive).
```

Chunk 3 (source: NetUnicorn Library: basic.py Tasks): 

```
Tasks from `netunicorn.library.tasks.basic`:\\n- `DummyTask()`: A simple task whose `run()` method returns `True`. Useful for testing pipeline functionality.\\n- `SleepTask(seconds: int)`: Causes the execution to pause for the specified number of `seconds`. Example: `SleepTask(10)` will sleep for 10 seconds.
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.basic import SleepTask
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline creation
pipeline = Pipeline()
pipeline.then(SleepTask(15))

# Node selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(2)

# Experiment object creation
experiment = Experiment()

# Environment definition
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name
experiment_name = "nl4netunicorn_experiment_{timestamp}"

# Delete old experiment
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)

# Poll for FINISHED
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 2. File System & Flags
Prompt: Create a script that runs on one node. First, it should get the current kernel version and set it as a flag named 'kernel_version'. Then, it should check the free disk space in '/tmp' and set that as a flag named 'tmp_free_space'. Finally, retrieve and print both flags.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script that runs on one node. First, it should get the current kernel version and set it as a flag named 'kernel_version'. Then, it should check the free disk space in '/tmp' and set that as a flag named 'tmp_free_space'. Finally, retrieve and print both flags."

Chunk 1 (source: NetUnicorn Library: flags.py Tasks): 

```
Tasks from `netunicorn.library.tasks.flags` for interacting with node-specific flags and system information:\\n- `SetFlagTask(name: str, value: str)`: Sets a key-value pair (flag) on the node. Can be retrieved later or by other tasks.\\n- `GetFlagTask(name: str)`: Retrieves the value of a previously set flag.\\n- `GetSerializationFormat()`: Returns the serialization format used by the minion (e.g., 'json', 'pickle').\\n- `CheckIPVersion(version: Literal[4, 6], bind_address: Optional[str] = None)`: Checks if the specified IP version (4 or 6) is connectable from the node, optionally trying to bind to a specific address.\\n- `GetOwnIP(version: Literal[4, 6])`: Returns the node\'s own IP address for the specified version.\\n- `CheckFreeSpace(path: str)`: Returns the free disk space (in bytes) at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary
```

Chunk 2 (source: NetUnicorn Library: flags.py Tasks): 

```
at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary shell `command` on the node. Returns `Success` with stdout or `Failure` with stderr.\\n- `Commands(commands: List[str])`: Executes a list of shell `commands` sequentially. Stops on first failure.\\n- `GetKernelVersion()`: Returns the kernel version string of the node.\\n- `Reboot(delay_seconds: int = 0)`: Reboots the machine after `delay_seconds`.
```

Chunk 3 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.flags import GetFlagTask, SetFlagTask, CheckFreeSpace, GetKernelVersion
from netunicorn.base.experiment import Experiment, ExperimentStatus
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline()
pipeline.then(GetKernelVersion().then(SetFlagTask(name='kernel_version'))).then(CheckFreeSpace(path='/tmp').then(SetFlagTask(name='tmp_free_space')))

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment Object and Definition
experiment = Experiment()
experiment.environment_definition = ShellExecution()
experiment.map(pipeline, working_nodes)

# Experiment Naming and Cleanup
experiment_name = "nl4netunicorn_experiment_{timestamp}"
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare the experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY status
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start the experiment execution
client.start_execution(experiment_name)

# Wait for the experiment to complete
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Retrieve and print results if FINISHED
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 3. Network Capture
Prompt: Write a NetUnicorn script to start a tcpdump capture on one node, saving to 'capture.pcap' for 30 seconds, then stop the capture. After stopping, use SendData to make 'capture.pcap' available.

### Retrieved Context:
Retrieved Context Chunks for: "Write a NetUnicorn script to start a tcpdump capture on one node, saving to 'capture.pcap' for 30 seconds, then stop the capture. After stopping, use SendData to make 'capture.pcap' available."

Chunk 1 (source: NetUnicorn Library: capture Tasks): 

```
Tasks from `netunicorn.library.tasks.capture` for network traffic capture:\\n- `capture.tcpdump.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tcpdump process, saving output to `filepath`. Custom `arguments` can be provided.\\n- `capture.tcpdump.StopNamedCapture(name: str)`: Stops a tcpdump process that was started with a specific `name` (referring to the `StartCapture` task name).\\n- `capture.tcpdump.StopAllCapture()`: Stops all currently running tcpdump processes initiated by the library on the node.\\n- `capture.tshark.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tshark process, saving output to `filepath`. Custom `arguments` can be provided.\\n- `capture.tshark.StopNamedCapture(name: str)`: Stops a tshark process started with a specific `name`.\\n- `capture.tshark.StopAllCapture()`: Stops all currently running tshark processes initiated by the library on the node.
```

Chunk 2 (source: NetUnicorn Library: preprocessing Tasks): 

```
Tasks from `netunicorn.library.tasks.preprocessing` for processing captured network data (e.g., pcap files) on the node:\\n- `preprocessing.scapy.Get5Tuples(filename: str)`: Reads a pcap file (`filename`) and extracts 5-tuples (src_ip, dst_ip, src_port, dst_port, proto) for TCP/UDP packets.\\n- `preprocessing.scapy.GetDNSQueries(filename: str)`: Extracts DNS query names from a pcap file.\\n- `preprocessing.scapy.GetHTTPHostHeaders(filename: str)`: Attempts to extract HTTP Host headers from raw packet data in a pcap file.\\n- `preprocessing.scapy.GetICMPRequests(filename: str)`: Extracts ICMP echo request packets from a pcap file.\\n- `preprocessing.scapy.GetUniqueARPMAC(filename: str)`: Extracts unique source MAC addresses from ARP packets in a pcap file.\\n- `preprocessing.tshark.TsharkCommand(command: list[str])`: Executes a given `tshark` command (provided as a list of strings) on the node.\\n- `preprocessing.zeek.ZeekPCAPAnalysis(pcap_filename: str, flags: Optional[list[str]] =
```

Chunk 3 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.capture import tcpdump
from netunicorn.library.tasks.data_transfer import SendData
from netunicorn.base.experiment import Experiment, ExperimentStatus
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline creation
pipeline = Pipeline()
capture_file = 'capture.pcap'

# Nodes selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment object creation
experiment = Experiment()
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name
experiment_name = "tcpdump_capture_experiment_{timestamp}"

# Delete old experiment if exists
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)

# Poll for FINISHED
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")

# SendData to make 'capture.pcap' available
pipeline.then(SendData(filepath=capture_file, task_name="tcpdump_capture", data_type="file"))
```

---

## 4. Measurement (Ookla Speedtest & Analysis)
Prompt: Develop a script that runs an Ookla speedtest on a single node. After the speedtest, use the OoklaSpeedtestAnalysis task to analyze the results. Print the analysis summary.

### Retrieved Context:
Retrieved Context Chunks for: "Develop a script that runs an Ookla speedtest on a single node. After the speedtest, use the OoklaSpeedtestAnalysis task to analyze the results. Print the analysis summary."

Chunk 1 (source: NetUnicorn Library: Example Pipelines (measurements)): 

```
to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not explicitly imported in this file, relying on its availability.\\nThese example pipelines demonstrate how to chain measurement tasks, data transfer tasks, and analysis tasks, and show potential integration patterns with external systems via environment variables like `RAG_ENDPOINT`.
```

Chunk 2 (source: NetUnicorn Library: measurements Tasks (General)): 

```
Callable[[list[ServerInfo]], str])`: Lists available Ookla servers and allows a user-provided `callback` function to choose one by returning its ID. `ServerInfo` is a dataclass with id, host, port, name, location, country.\\n- `measurements.ookla_speedtest.OoklaSpeedtestAnalysis(speedtest_task_name: str)`: Analyzes the JSON results from a previous `OoklaSpeedtest` task (identified by `speedtest_task_name`). It classifies latency (good, ok, strange, problem) and throughput (low, ok, good, excellent) and returns a summary dictionary.\\n- `measurements.ping.Ping(host: str, count: Optional[int] = None, interval: Optional[float] = None, timeout: Optional[float] = None, interface: Optional[str] = None)`: Performs an ICMP ping to `host` with options for count, interval, timeout, and source interface.
```

Chunk 3 (source: NetUnicorn Library: Example Pipelines (measurements)): 

```
The `netunicorn.library.pipelines.measurements` module provides example pre-defined pipelines:\\n- `pipelines.measurements.ookla_speedtest.simple_speedtest_pipeline() -> Pipeline`: Defines a pipeline that runs `OoklaSpeedtest` and then `OoklaSpeedtestAnalysis` on its results. A good example of a simple measurement and analysis sequence.\\n- `pipelines.measurements.netflex_pipeline.netflex_ookla_full_loop_pipeline() -> Pipeline`: Runs `OoklaSpeedtest`, then uses `SendData` to send results to an endpoint defined by the `RAG_ENDPOINT` environment variable, and then uses `FetchData` to retrieve data from the same endpoint. This suggests an integration pattern with an external RAG/analysis system.\\n- `pipelines.measurements.netflex_pipeline.netflex_mlab_full_loop_pipeline() -> Pipeline`: Similar to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not
```

### Generated Code:
```python
# Imports
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.measurements.ookla_speedtest import OoklaSpeedtest, OoklaSpeedtestAnalysis
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials (will be injected)
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline
pipeline = Pipeline()
pipeline.then(OoklaSpeedtest())
pipeline.then(OoklaSpeedtestAnalysis("OoklaSpeedtest"))

# Nodes
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment object creation
experiment = Experiment()

# Environment definition
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name (unique)
experiment_name = "ookla_speedtest_experiment_{timestamp}"

# Delete old experiment (try/except)
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e: # Catch any other potential exceptions during deletion
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10) # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)

# Poll for FINISHED
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20) # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report: # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
         print(f"Error: {final_status_info.error}")
```

---

## 5. Measurement (Ping)
Prompt: Generate a script that pings 'google.com' 10 times from one node, with a 0.5 second interval. Print the full ping results.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script that pings 'google.com' 10 times from one node, with a 0.5 second interval. Print the full ping results."

Chunk 1 (source: NetUnicorn Library: Example Pipelines (measurements)): 

```
to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not explicitly imported in this file, relying on its availability.\\nThese example pipelines demonstrate how to chain measurement tasks, data transfer tasks, and analysis tasks, and show potential integration patterns with external systems via environment variables like `RAG_ENDPOINT`.
```

Chunk 2 (source: NetUnicorn Library: measurements Tasks (Specialized)): 

```
Specialized measurement tasks from submodules of `netunicorn.library.tasks.measurements`:\\n- `measurements.alexa.alexa.AlexaWebsitesTask(num_of_websites: int)`: Performs network measurements (curl, dig, traceroute, ping) to the top `num_of_websites` from the Alexa Top 1 Million list.\\n- `measurements.cloudflare.speedtest.CloudflareSpeedTest(count: int = 3, warmup_bytes: int = 100000)`: Runs a speed test using Cloudflare's network, performing `count` tests after a warmup phase. (Dispatcher for `CloudflareSpeedTestLinuxImplementation`)
```

Chunk 3 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.ping import Ping
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline().then(Ping(host="google.com", count=10, interval=0.5))

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment object creation
experiment = Experiment()
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name
experiment_name = "ping_google_experiment_{timestamp}"

# Delete old experiment
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)

# Poll for FINISHED
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 6. Data Transfer & Preprocessing (Hypothetical Chain)
Prompt: Create a script for two nodes. Node 1 runs an `ExecuteShellCommand` to create a dummy text file named 'mydata.txt' with content 'Hello NetUnicorn'. Node 1 then uses `SendData` to make 'mydata.txt' available. Node 2 uses `FetchData` to get 'mydata.txt', then runs `ExecuteShellCommand` to print its content using `cat mydata.txt`.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script for two nodes. Node 1 runs an `ExecuteShellCommand` to create a dummy text file named 'mydata.txt' with content 'Hello NetUnicorn'. Node 1 then uses `SendData` to make 'mydata.txt' available. Node 2 uses `FetchData` to get 'mydata.txt', then runs `ExecuteShellCommand` to print its content using `cat mydata.txt`."

Chunk 1 (source: NetUnicorn Library: data_transfer Tasks): 

```
Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal["ookla-speedtest", "pcp-speedtest", "iperf3", "netperf", "flent", "file"] = "file", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task.
```

Chunk 2 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 3 (source: NetUnicorn Library: flags.py Tasks): 

```
at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary shell `command` on the node. Returns `Success` with stdout or `Failure` with stderr.\\n- `Commands(commands: List[str])`: Executes a list of shell `commands` sequentially. Stops on first failure.\\n- `GetKernelVersion()`: Returns the kernel version string of the node.\\n- `Reboot(delay_seconds: int = 0)`: Reboots the machine after `delay_seconds`.
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.data_transfer import SendData, FetchData
from netunicorn.library.tasks.shell import ExecuteShellCommand
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline()

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(2)  # Select two nodes

# Experiment object creation
experiment = Experiment()

# Environment definition
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name
experiment_name = "my_experiment_{timestamp}"  # Unique experiment name

# Delete old experiment
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:  # Catch any other potential exceptions during deletion
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Add tasks to the pipeline
pipeline.then(ExecuteShellCommand("echo 'Hello NetUnicorn' > mydata.txt"))  # Node 1 creates 'mydata.txt'
pipeline.then(SendData("mydata.txt", "send_data_task", data_type="file"))  # Node 1 makes 'mydata.txt' available

# Fetch 'mydata.txt' on Node 2 and print its content
pipeline.then(FetchData("send_data_task", working_nodes[1].name))  # Node 2 fetches 'mydata.txt'
pipeline.then(ExecuteShellCommand("cat mydata.txt"))  # Node 2 prints the content of 'mydata.txt'

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)
print(f"Experiment {experiment_name} started. Waiting for completion...")

# Poll for FINISHED
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 7. Video Watching (Simple YouTube)
Prompt: Write a script to watch the YouTube video 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' for 20 seconds on one node. Use the simple YouTube watcher.

### Retrieved Context:
Retrieved Context Chunks for: "Write a script to watch the YouTube video 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' for 20 seconds on one node. Use the simple YouTube watcher."

Chunk 1 (source: NetUnicorn Library: video_watchers Tasks): 

```
Selenium-based tasks from `netunicorn.library.tasks.video_watchers` for watching online videos. These are simpler watchers compared to the `qoe_youtube` one and do not involve QoE metric collection extensions by default.\\n- `video_watchers.twitch_watcher.WatchTwitchStream(video_url: str, duration: Optional[int] = 10, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Twitch stream at `video_url` for `duration` seconds. Uses a headless Chrome/Chromium environment via Xvfb.\\n- `video_watchers.vimeo_watcher.WatchVimeoVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Vimeo video at `video_url`. If `duration` is provided, watches for that many seconds. If `duration` is None, it attempts to watch until the video ends by checking player state.\\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(video_url: str, duration: Optional[int] = 100,
```

Chunk 2 (source: NetUnicorn Library: video_watchers Tasks): 

```
If `duration` is None, it attempts to watch until the video ends by checking player state.\\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a YouTube video at `video_url`. Similar to the Vimeo watcher, it can watch for a fixed `duration` or attempt to watch until the end by checking player state via JavaScript. Uses `YouTubeIFrameStatus` enum for player states.\\nAll these watchers are TaskDispatchers that delegate to Linux-specific implementations which handle Selenium and Xvfb setup (typically requiring `chromium`, `chromium-driver`, `xvfb`, `selenium`). The default `chrome_location` is often `/usr/bin/chromium`.
```

Chunk 3 (source: NetUnicorn Library: qoe_youtube Tasks): 

```
= None, quality: Optional[int] = None, qoe_server_address: str = "localhost", qoe_server_port: int = 34543, report_time: int = 250)`: Watches a YouTube `video_url` using Selenium and two Chrome extensions (an adblocker and a custom QoE stats collector). It sends QoE metrics (player state, quality changes, periodic stats) to the specified `qoe_server_address:qoe_server_port`. `duration` specifies watch time (None for full video). `quality` can request a specific resolution. `report_time` is the interval for sending periodic stats (in ms). (Dispatcher for Linux implementation with extensive Selenium/Chrome/extension setup requirements). The underlying watcher logic is in `watcher.py`.
```

### Generated Code:
```python
# Imports
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.video_watchers.youtube_watcher import WatchYouTubeVideo
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials (will be injected)
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline
pipeline = Pipeline()
pipeline.then(WatchYouTubeVideo("https://www.youtube.com/watch?v=dQw4w9WgXcQ", duration=20))

# Nodes
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment object creation
experiment = Experiment()

# Environment definition
experiment.environment_definition = ShellExecution()

# Experiment mapping
experiment.map(pipeline, working_nodes)

# Experiment name (unique)
experiment_name = "nl4netunicorn_experiment_{timestamp}"

# Delete old experiment (try/except)
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e: # Catch any other potential exceptions during deletion
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10) # Poll every 10 seconds

# Start experiment
client.start_execution(experiment_name)

# Poll for FINISHED
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20) # Poll every 20 seconds

# Get and print results
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report: # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
         print(f"Error: {final_status_info.error}")
```

---

## 8. File Upload (File.io)
Prompt: Generate a script that first creates a small text file named 'upload_test.txt' with some sample text on one node. Then, upload this file to file.io with a 1-day expiration. Print the file.io link from the result.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script that first creates a small text file named 'upload_test.txt' with some sample text on one node. Then, upload this file to file.io with a 1-day expiration. Print the file.io link from the result."

Chunk 1 (source: NetUnicorn Library: upload Tasks): 

```
Tasks from `netunicorn.library.tasks.upload` for uploading files from the node to various destinations:\\n- `upload.fileio.UploadToFileIO(filepath: str, expires: str = "14d")`: Uploads the local file at `filepath` to `file.io`, a temporary file sharing service. The `expires` parameter (e.g., "1d", "1w") controls expiration. (Uses curl).\\n- `upload.ftp.UploadToFTP(local_filepath: str, ftp_url: str, username: str, password: str, destination_dir: str = "/", timeout: int = 30)`: Uploads `local_filepath` to an FTP server at `ftp_url` using `username` and `password`, into `destination_dir`.\\n- `upload.ftp.RetrieveFromFTP(ftp_remote_filepath: str, ftp_url: str, username: str, password: str, local_dir: str = "./", timeout: int = 30)`: Downloads `ftp_remote_filepath` from an FTP server to the `local_dir`.\\n- `upload.googlecloud.UploadToGoogleCloudStorage(local_filepath: str, bucket: str, target_filepath: str = "", auth_token: Optional[str] = None)`: Uploads `local_filepath` to the specified
```

Chunk 2 (source: NetUnicorn Library: data_transfer Tasks): 

```
Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal["ookla-speedtest", "pcp-speedtest", "iperf3", "netperf", "flent", "file"] = "file", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task.
```

Chunk 3 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.upload.fileio import UploadToFileIO
from netunicorn.base.experiment import Experiment, ExperimentStatus
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline()
pipeline.then(UploadToFileIO("upload_test.txt", expires="1d"))

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment Object and Definition
experiment = Experiment()
experiment.environment_definition = ShellExecution()
experiment.map(pipeline, working_nodes)

# Experiment Naming and Cleanup
experiment_name = "nl4netunicorn_experiment_{timestamp}"
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare the experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY status
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start the experiment execution
client.start_execution(experiment_name)
print(f"Experiment {experiment_name} started. Waiting for completion...")

# Wait for the experiment to complete
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Retrieve and print results if FINISHED
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 9. Network Attack (LAND Attack - USE WITH EXTREME CAUTION AND ONLY ON ISOLATED TEST NETWORKS)
Prompt: Generate a script to perform a LAND attack against IP '192.168.1.100' using source port 1337 and destination port 80 on one node. (Warning: Only for use in controlled, isolated test environments).

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script to perform a LAND attack against IP '192.168.1.100' using source port 1337 and destination port 80 on one node. (Warning: Only for use in controlled, isolated test environments)."

Chunk 1 (source: NetUnicorn Library: network_attacks Tasks): 

```
`network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a JNDI lookup at `cc_address`.\\n- `network_attacks.loris.SlowLoris(host: str, port: int = 80, sockets: int = 150, https: bool = False, sleeptime: int = 15, slowloris_iterations: int = 100)`: Performs a Slowloris denial-of-service attack.\\n- `network_attacks.loris.SMBLoris(host: str, starting_source_port: int = 10000, number_of_ports: int = 1000)`: Performs a resource exhaustion attack against SMB (port 445).\\n- `network_attacks.mac.MACFlooder(iface: str = "eth0", count: int = 1000)`: Floods the network with Ethernet frames with random MAC addresses to overwhelm switch CAM tables.\\n- `network_attacks.mail.FakeMail(host: str, port: int, sender: str, recipient: str, subject: str, body: str)`: Sends an email using raw SMTP commands (potentially for spoofing, use with caution).\\n-
```

Chunk 2 (source: NetUnicorn Library: network_attacks Tasks): 

```
port: int = 443, count: int = 1, length: int = 0xFFFF, tls_version: Literal["tls10", "tls11", "tls12"] = "tls11", starttls_proto: Optional[str] = None, data: Optional[str] = None)`: Tests for the Heartbleed vulnerability (CVE-2014-0160).\\n- `network_attacks.heartbleed2.Heartbleed(IPaddress: str, port: int, starttls: bool = False, debug: bool = False)`: An alternative implementation for testing Heartbleed.\\n- `network_attacks.icmp.ICMPRedirection(target: str, old_gw: str, new_gw: str)`: Sends ICMP redirect packets to `target`, instructing it to use `new_gw` instead of `old_gw`.\\n- `network_attacks.land.LANDAttack(target_ip: str, source_port: int = 1001, destination_port: int = 80)`: Performs a LAND attack by sending a packet with the same source and destination IP/port to `target_ip`.\\n- `network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a
```

Chunk 3 (source: NetUnicorn Library: network_attacks Tasks): 

```
Tasks from `netunicorn.library.tasks.network_attacks` and its submodules, for simulating various network attacks. Use responsibly and only on authorized systems.\\n- `network_attacks.arp.ArpSpoof(target_ip: str, spoof_ip: str, interface: str = "eth0", duration_seconds: int = 60)`: Performs ARP spoofing between `target_ip` and `spoof_ip` on the given `interface` for `duration_seconds`.\\n- `network_attacks.cve202141773.CVE202141773(target: str, path: str = "/cgi-bin/.%2e/%2e%2e/%2e%2e/etc/passwd")`: Attempts to exploit Apache path traversal (CVE-2021-41773) against `target` using the specified `path`.\\n- `network_attacks.ftp.BruteForceFTP(target: str, username: str, wordlist: list[str])`: Attempts to brute-force FTP login credentials.\\n- `network_attacks.heartbleed.Heartbleed(host: str, port: int = 443, count: int = 1, length: int = 0xFFFF, tls_version: Literal["tls10", "tls11", "tls12"] = "tls11", starttls_proto: Optional[str] = None, data: Optional[str] = None)`: Tests for the
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.land import LANDAttack
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline()
land_task = LANDAttack(target_ip="192.168.1.100", source_port=1337, destination_port=80)
pipeline.then(land_task)

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment Object and Definition
experiment = Experiment()
experiment.environment_definition = ShellExecution()
experiment.map(pipeline, working_nodes)

# Experiment Naming and Cleanup
experiment_name = "land_attack_experiment_{timestamp}"
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare the experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY status
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start the experiment execution
client.start_execution(experiment_name)

# Wait for the experiment to complete (poll for FINISHED status)
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Retrieve and print results if FINISHED
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

## 10. Utility (Port Knock)
Prompt: Create a script that performs a port knock on IP '10.0.0.1' to port 12345 from one node.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script that performs a port knock on IP '10.0.0.1' to port 12345 from one node."

Chunk 1 (source: NetUnicorn Library: utils Tasks): 

```
General utility tasks from `netunicorn.library.tasks.utils`:\\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a "knock") to the specified `ip` and `port`. Does not return success/failure of the knock itself, always returns 0.\\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) which will sleep for a random duration between `seconds_min` and `seconds_max` (inclusive).
```

Chunk 2 (source: NetUnicorn Full Script Structure Example): 

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 3 (source: NetUnicorn Library: network_attacks Tasks): 

```
`network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a JNDI lookup at `cc_address`.\\n- `network_attacks.loris.SlowLoris(host: str, port: int = 80, sockets: int = 150, https: bool = False, sleeptime: int = 15, slowloris_iterations: int = 100)`: Performs a Slowloris denial-of-service attack.\\n- `network_attacks.loris.SMBLoris(host: str, starting_source_port: int = 10000, number_of_ports: int = 1000)`: Performs a resource exhaustion attack against SMB (port 445).\\n- `network_attacks.mac.MACFlooder(iface: str = "eth0", count: int = 1000)`: Floods the network with Ethernet frames with random MAC addresses to overwhelm switch CAM tables.\\n- `network_attacks.mail.FakeMail(host: str, port: int, sender: str, recipient: str, subject: str, body: str)`: Sends an email using raw SMTP commands (potentially for spoofing, use with caution).\\n-
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient, RemoteClientException
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.utils import PortKnock
from netunicorn.base.experiment import Experiment, ExperimentStatus
from netunicorn.base.environment_definitions import ShellExecution
from netunicorn.base.nodes import NodePool
import time

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint=endpoint, login=login, password=password)

# Pipeline Creation
pipeline = Pipeline().then(PortKnock(ip="10.0.0.1", port=12345))

# Node Selection
node_pool = client.get_nodes()
working_nodes = node_pool.take(1)

# Experiment Object and Definition
experiment = Experiment()
experiment.environment_definition = ShellExecution()
experiment.map(pipeline, working_nodes)

# Experiment Naming and Cleanup
experiment_name = "port_knock_experiment_{timestamp}"
try:
    client.delete_experiment(experiment_name)
    print(f"Successfully deleted pre-existing experiment: {experiment_name}")
except RemoteClientException as e:
    print(f"Info: Could not delete experiment {experiment_name} (may not exist or already deleted): {e}")
except Exception as e:
    print(f"Warning: An unexpected error occurred while trying to delete experiment {experiment_name}: {e}")

# Prepare the experiment
client.prepare_experiment(experiment, experiment_name)

# Poll for READY
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status == ExperimentStatus.READY:
        print("Experiment is READY.")
        break
    time.sleep(10)  # Poll every 10 seconds

# Start the experiment execution
client.start_execution(experiment_name)

# Wait for the experiment to complete
print(f"Experiment {experiment_name} started. Waiting for completion...")
while True:
    status = client.get_experiment_status(experiment_name).status
    print(f"Current status: {status}")
    if status != ExperimentStatus.RUNNING:
        break
    time.sleep(20)  # Poll every 20 seconds

# Retrieve and print results if FINISHED
final_status_info = client.get_experiment_status(experiment_name)
if final_status_info.status == ExperimentStatus.FINISHED:
    results = final_status_info.execution_result
    print(f"Experiment results: {results}")
    if results:
        for report_list in results:
            for report in report_list:
                if report:  # Report can be None if a node fails
                    print(f"Node: {report.node.name}, Success: {report.success}, Log: {report.log}")
                    if not report.success:
                        print(f"Error details: {report.error}")
else:
    print(f"Experiment did not finish successfully. Final status: {final_status_info.status}")
    if final_status_info.error:
        print(f"Error: {final_status_info.error}")
```

---

