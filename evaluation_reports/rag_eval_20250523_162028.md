# NetUnicorn RAG Evaluation Report
Generated: 2025-05-23T16:20:28.797582

## 1. Basic Task
Prompt: Generate a NetUnicorn script that selects two available nodes and makes each of them sleep for 15 seconds. Then, print the results.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a NetUnicorn script that selects two available nodes and makes each of them sleep for 15 seconds. Then, print the results."

Chunk 1 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 2 (source: NetUnicorn Library: utils Tasks):

```
General utility tasks from `netunicorn.library.tasks.utils`:\\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a "knock") to the specified `ip` and `port`. Does not return success/failure of the knock itself, always returns 0.\\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) which will sleep for a random duration between `seconds_min` and `seconds_max` (inclusive).
```

Chunk 3 (source: NetUnicorn Library: basic.py Tasks):

```
Tasks from `netunicorn.library.tasks.basic`:\\n- `DummyTask()`: A simple task whose `run()` method returns `True`. Useful for testing pipeline functionality.\\n- `SleepTask(seconds: int)`: Causes the execution to pause for the specified number of `seconds`. Example: `SleepTask(10)` will sleep for 10 seconds.
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.sleep import SleepTask

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define the pipeline with SleepTask(15) for each node
pipeline = Pipeline().then(SleepTask(15))

# Get available nodes and select two
nodes = client.get_nodes()
working_nodes = nodes.take(2)

# Define experiment name
experiment_name = "nl4netunicorn_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)

# Start the experiment execution
client.start_execution(experiment_name)

# Wait for the experiment to complete
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 2. File System & Flags
Prompt: Create a script that runs on one node. First, it should get the current kernel version and set it as a flag named 'kernel_version'. Then, it should check the free disk space in '/tmp' and set that as a flag named 'tmp_free_space'. Finally, retrieve and print both flags.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script that runs on one node. First, it should get the current kernel version and set it as a flag named 'kernel_version'. Then, it should check the free disk space in '/tmp' and set that as a flag named 'tmp_free_space'. Finally, retrieve and print both flags."

Chunk 1 (source: NetUnicorn Library: flags.py Tasks):

```
Tasks from `netunicorn.library.tasks.flags` for interacting with node-specific flags and system information:\\n- `SetFlagTask(name: str, value: str)`: Sets a key-value pair (flag) on the node. Can be retrieved later or by other tasks.\\n- `GetFlagTask(name: str)`: Retrieves the value of a previously set flag.\\n- `GetSerializationFormat()`: Returns the serialization format used by the minion (e.g., 'json', 'pickle').\\n- `CheckIPVersion(version: Literal[4, 6], bind_address: Optional[str] = None)`: Checks if the specified IP version (4 or 6) is connectable from the node, optionally trying to bind to a specific address.\\n- `GetOwnIP(version: Literal[4, 6])`: Returns the node\'s own IP address for the specified version.\\n- `CheckFreeSpace(path: str)`: Returns the free disk space (in bytes) at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary
```

Chunk 2 (source: NetUnicorn Library: flags.py Tasks):

```
at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary shell `command` on the node. Returns `Success` with stdout or `Failure` with stderr.\\n- `Commands(commands: List[str])`: Executes a list of shell `commands` sequentially. Stops on first failure.\\n- `GetKernelVersion()`: Returns the kernel version string of the node.\\n- `Reboot(delay_seconds: int = 0)`: Reboots the machine after `delay_seconds`.
```

Chunk 3 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.flags import GetKernelVersion, CheckFreeSpace, SetFlagTask, GetFlagTask
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define pipeline
pipeline = Pipeline()
pipeline.then(GetKernelVersion()) \
        .then(SetFlagTask(name='kernel_version', value='{{task_result}}')) \
        .then(CheckFreeSpace(path='/tmp')) \
        .then(SetFlagTask(name='tmp_free_space', value='{{task_result}}')) \
        .then(GetFlagTask(name='kernel_version')) \
        .then(GetFlagTask(name='tmp_free_space'))

# Get available nodes and select one
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "nl4netunicorn_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare, start, and wait for the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 3. Network Capture
Prompt: Write a NetUnicorn script to start a tcpdump capture on one node, saving to 'capture.pcap' for 30 seconds, then stop the capture. After stopping, use SendData to make 'capture.pcap' available.

### Retrieved Context:
Retrieved Context Chunks for: "Write a NetUnicorn script to start a tcpdump capture on one node, saving to 'capture.pcap' for 30 seconds, then stop the capture. After stopping, use SendData to make 'capture.pcap' available."

Chunk 1 (source: NetUnicorn Library: capture Tasks):

```
Tasks from `netunicorn.library.tasks.capture` for network traffic capture:\\n- `capture.tcpdump.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tcpdump process, saving output to `filepath`. Custom `arguments` can be provided.\\n- `capture.tcpdump.StopNamedCapture(name: str)`: Stops a tcpdump process that was started with a specific `name` (referring to the `StartCapture` task name).\\n- `capture.tcpdump.StopAllCapture()`: Stops all currently running tcpdump processes initiated by the library on the node.\\n- `capture.tshark.StartCapture(filepath: str, arguments: Optional[List[str]] = None)`: Starts a tshark process, saving output to `filepath`. Custom `arguments` can be provided.\\n- `capture.tshark.StopNamedCapture(name: str)`: Stops a tshark process started with a specific `name`.\\n- `capture.tshark.StopAllCapture()`: Stops all currently running tshark processes initiated by the library on the node.
```

Chunk 2 (source: NetUnicorn Library: preprocessing Tasks):

```
Tasks from `netunicorn.library.tasks.preprocessing` for processing captured network data (e.g., pcap files) on the node:\\n- `preprocessing.scapy.Get5Tuples(filename: str)`: Reads a pcap file (`filename`) and extracts 5-tuples (src_ip, dst_ip, src_port, dst_port, proto) for TCP/UDP packets.\\n- `preprocessing.scapy.GetDNSQueries(filename: str)`: Extracts DNS query names from a pcap file.\\n- `preprocessing.scapy.GetHTTPHostHeaders(filename: str)`: Attempts to extract HTTP Host headers from raw packet data in a pcap file.\\n- `preprocessing.scapy.GetICMPRequests(filename: str)`: Extracts ICMP echo request packets from a pcap file.\\n- `preprocessing.scapy.GetUniqueARPMAC(filename: str)`: Extracts unique source MAC addresses from ARP packets in a pcap file.\\n- `preprocessing.tshark.TsharkCommand(command: list[str])`: Executes a given `tshark` command (provided as a list of strings) on the node.\\n- `preprocessing.zeek.ZeekPCAPAnalysis(pcap_filename: str, flags: Optional[list[str]] =
```

Chunk 3 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.capture import tcpdump
from netunicorn.library.tasks.data_transfer import SendData

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define the pipeline
pipeline = Pipeline()

# Start tcpdump capture for 30 seconds
capture_filepath = 'capture.pcap'
capture_duration = 30
pipeline.then(tcpdump.StartCapture(capture_filepath, arguments=['-G', str(capture_duration)]))

# Stop the tcpdump capture
pipeline.then(tcpdump.StopNamedCapture(capture_filepath))

# Make 'capture.pcap' available for fetching
pipeline.then(SendData(capture_filepath, task_name='capture_task', data_type='pcap', local_filepath_is_temporary=False))

# Get available nodes and select one
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "tcpdump_capture_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare, start, and wait for the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 4. Measurement (Ookla Speedtest & Analysis)
Prompt: Develop a script that runs an Ookla speedtest on a single node. After the speedtest, use the OoklaSpeedtestAnalysis task to analyze the results. Print the analysis summary.

### Retrieved Context:
Retrieved Context Chunks for: "Develop a script that runs an Ookla speedtest on a single node. After the speedtest, use the OoklaSpeedtestAnalysis task to analyze the results. Print the analysis summary."

Chunk 1 (source: NetUnicorn Library: Example Pipelines (measurements)):

```
to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not explicitly imported in this file, relying on its availability.\\nThese example pipelines demonstrate how to chain measurement tasks, data transfer tasks, and analysis tasks, and show potential integration patterns with external systems via environment variables like `RAG_ENDPOINT`.
```

Chunk 2 (source: NetUnicorn Library: measurements Tasks (General)):

```
Callable[[list[ServerInfo]], str])`: Lists available Ookla servers and allows a user-provided `callback` function to choose one by returning its ID. `ServerInfo` is a dataclass with id, host, port, name, location, country.\\n- `measurements.ookla_speedtest.OoklaSpeedtestAnalysis(speedtest_task_name: str)`: Analyzes the JSON results from a previous `OoklaSpeedtest` task (identified by `speedtest_task_name`). It classifies latency (good, ok, strange, problem) and throughput (low, ok, good, excellent) and returns a summary dictionary.\\n- `measurements.ping.Ping(host: str, count: Optional[int] = None, interval: Optional[float] = None, timeout: Optional[float] = None, interface: Optional[str] = None)`: Performs an ICMP ping to `host` with options for count, interval, timeout, and source interface.
```

Chunk 3 (source: NetUnicorn Library: Example Pipelines (measurements)):

```
The `netunicorn.library.pipelines.measurements` module provides example pre-defined pipelines:\\n- `pipelines.measurements.ookla_speedtest.simple_speedtest_pipeline() -> Pipeline`: Defines a pipeline that runs `OoklaSpeedtest` and then `OoklaSpeedtestAnalysis` on its results. A good example of a simple measurement and analysis sequence.\\n- `pipelines.measurements.netflex_pipeline.netflex_ookla_full_loop_pipeline() -> Pipeline`: Runs `OoklaSpeedtest`, then uses `SendData` to send results to an endpoint defined by the `RAG_ENDPOINT` environment variable, and then uses `FetchData` to retrieve data from the same endpoint. This suggests an integration pattern with an external RAG/analysis system.\\n- `pipelines.measurements.netflex_pipeline.netflex_mlab_full_loop_pipeline() -> Pipeline`: Similar to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.measurements.ookla_speedtest import OoklaSpeedtest, OoklaSpeedtestAnalysis
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define the pipeline
pipeline = Pipeline()
pipeline.then(OoklaSpeedtest())
pipeline.then(OoklaSpeedtestAnalysis("OoklaSpeedtest"))

# Get all available nodes
nodes = client.get_nodes()

# Filter nodes if needed, otherwise select one available node
working_nodes = nodes.take(1)

# Experiment name
experiment_name = "nl4netunicorn_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)

# Start the experiment execution
client.start_execution(experiment_name)

# Wait for the experiment to complete
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 5. Measurement (Ping)
Prompt: Generate a script that pings 'google.com' 10 times from one node, with a 0.5 second interval. Print the full ping results.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script that pings 'google.com' 10 times from one node, with a 0.5 second interval. Print the full ping results."

Chunk 1 (source: NetUnicorn Library: Example Pipelines (measurements)):

```
to the Ookla loop, but runs `NDT7SpeedTest` (with JSON format), then `SendData` (type "mlab-speedtest") to `RAG_ENDPOINT`, and `FetchData` from `RAG_ENDPOINT`. Note: `NDT7SpeedTest` is used but not explicitly imported in this file, relying on its availability.\\nThese example pipelines demonstrate how to chain measurement tasks, data transfer tasks, and analysis tasks, and show potential integration patterns with external systems via environment variables like `RAG_ENDPOINT`.
```

Chunk 2 (source: NetUnicorn Library: measurements Tasks (Specialized)):

```
Specialized measurement tasks from submodules of `netunicorn.library.tasks.measurements`:\\n- `measurements.alexa.alexa.AlexaWebsitesTask(num_of_websites: int)`: Performs network measurements (curl, dig, traceroute, ping) to the top `num_of_websites` from the Alexa Top 1 Million list.\\n- `measurements.cloudflare.speedtest.CloudflareSpeedTest(count: int = 3, warmup_bytes: int = 100000)`: Runs a speed test using Cloudflare's network, performing `count` tests after a warmup phase. (Dispatcher for `CloudflareSpeedTestLinuxImplementation`)
```

Chunk 3 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.ping import Ping
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = 'https://pinot.cs.ucsb.edu/netunicorn'
login = '293nmay25'
password = '4Ij9Du65jrqj'

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define the ping task
ping_task = Ping('google.com', count=10, interval=0.5)

# Get available nodes and select one
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "ping_google_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Create pipeline and add the ping task
pipeline = Pipeline().then(ping_task)

# Prepare, start, and wait for the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 6. Data Transfer & Preprocessing (Hypothetical Chain)
Prompt: Create a script for two nodes. Node 1 runs an `ExecuteShellCommand` to create a dummy text file named 'mydata.txt' with content 'Hello NetUnicorn'. Node 1 then uses `SendData` to make 'mydata.txt' available. Node 2 uses `FetchData` to get 'mydata.txt', then runs `ExecuteShellCommand` to print its content using `cat mydata.txt`.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script for two nodes. Node 1 runs an `ExecuteShellCommand` to create a dummy text file named 'mydata.txt' with content 'Hello NetUnicorn'. Node 1 then uses `SendData` to make 'mydata.txt' available. Node 2 uses `FetchData` to get 'mydata.txt', then runs `ExecuteShellCommand` to print its content using `cat mydata.txt`."

Chunk 1 (source: NetUnicorn Library: data_transfer Tasks):

```
Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal["ookla-speedtest", "pcp-speedtest", "iperf3", "netperf", "flent", "file"] = "file", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task.
```

Chunk 2 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 3 (source: NetUnicorn Library: flags.py Tasks):

```
at the given `path` on the node.\\n- `GetCurrentDirectory()`: Returns the current working directory of the task execution on the node.\\n- `ExecuteShellCommand(command: str)`: Executes an arbitrary shell `command` on the node. Returns `Success` with stdout or `Failure` with stderr.\\n- `Commands(commands: List[str])`: Executes a list of shell `commands` sequentially. Stops on first failure.\\n- `GetKernelVersion()`: Returns the kernel version string of the node.\\n- `Reboot(delay_seconds: int = 0)`: Reboots the machine after `delay_seconds`.
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.data_transfer import SendData, FetchData
from netunicorn.library.tasks.shell import ExecuteShellCommand
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define pipeline
pipeline = Pipeline()

# Define task for Node 1
node1_task = ExecuteShellCommand("echo 'Hello NetUnicorn' > mydata.txt")

# Define task for Node 2
node2_task = ExecuteShellCommand("cat mydata.txt")

# Add tasks to the pipeline
pipeline.then(node1_task).then(SendData("mydata.txt", "dummy_task", data_type="file"))

# Get all available nodes
nodes = client.get_nodes()

# Filter nodes if needed, otherwise select the first node
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "my_data_transfer_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)

# Start the experiment
client.start_execution(experiment_name)

# Wait for the experiment to complete
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 7. Video Watching (Simple YouTube)
Prompt: Write a script to watch the YouTube video 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' for 20 seconds on one node. Use the simple YouTube watcher.

### Retrieved Context:
Retrieved Context Chunks for: "Write a script to watch the YouTube video 'https://www.youtube.com/watch?v=dQw4w9WgXcQ' for 20 seconds on one node. Use the simple YouTube watcher."

Chunk 1 (source: NetUnicorn Library: video_watchers Tasks):

```
Selenium-based tasks from `netunicorn.library.tasks.video_watchers` for watching online videos. These are simpler watchers compared to the `qoe_youtube` one and do not involve QoE metric collection extensions by default.\\n- `video_watchers.twitch_watcher.WatchTwitchStream(video_url: str, duration: Optional[int] = 10, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Twitch stream at `video_url` for `duration` seconds. Uses a headless Chrome/Chromium environment via Xvfb.\\n- `video_watchers.vimeo_watcher.WatchVimeoVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a Vimeo video at `video_url`. If `duration` is provided, watches for that many seconds. If `duration` is None, it attempts to watch until the video ends by checking player state.\\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(video_url: str, duration: Optional[int] = 100,
```

Chunk 2 (source: NetUnicorn Library: video_watchers Tasks):

```
If `duration` is None, it attempts to watch until the video ends by checking player state.\\n- `video_watchers.youtube_watcher.WatchYouTubeVideo(video_url: str, duration: Optional[int] = 100, chrome_location: Optional[str] = None, webdriver_arguments: Optional[list] = None)`: Watches a YouTube video at `video_url`. Similar to the Vimeo watcher, it can watch for a fixed `duration` or attempt to watch until the end by checking player state via JavaScript. Uses `YouTubeIFrameStatus` enum for player states.\\nAll these watchers are TaskDispatchers that delegate to Linux-specific implementations which handle Selenium and Xvfb setup (typically requiring `chromium`, `chromium-driver`, `xvfb`, `selenium`). The default `chrome_location` is often `/usr/bin/chromium`.
```

Chunk 3 (source: NetUnicorn Library: qoe_youtube Tasks):

```
= None, quality: Optional[int] = None, qoe_server_address: str = "localhost", qoe_server_port: int = 34543, report_time: int = 250)`: Watches a YouTube `video_url` using Selenium and two Chrome extensions (an adblocker and a custom QoE stats collector). It sends QoE metrics (player state, quality changes, periodic stats) to the specified `qoe_server_address:qoe_server_port`. `duration` specifies watch time (None for full video). `quality` can request a specific resolution. `report_time` is the interval for sending periodic stats (in ms). (Dispatcher for Linux implementation with extensive Selenium/Chrome/extension setup requirements). The underlying watcher logic is in `watcher.py`.
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.video_watchers.youtube_watcher import WatchYouTubeVideo
from netunicorn.base.nodes import NodePool

# Credentials
client = RemoteClient("https://pinot.cs.ucsb.edu/netunicorn", "293nmay25", "4Ij9Du65jrqj")

# Client Initialization
client = RemoteClient("https://pinot.cs.ucsb.edu/netunicorn", "293nmay25", "4Ij9Du65jrqj")

# Pipeline Creation
pipeline = Pipeline()
pipeline.then(WatchYouTubeVideo("https://www.youtube.com/watch?v=dQw4w9WgXcQ", duration=20))

# Node Selection
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Experiment Naming
experiment_name = "nl4netunicorn_experiment"

# Delete pre-existing experiment
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Experiment Lifecycle & Results
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 8. File Upload (File.io)
Prompt: Generate a script that first creates a small text file named 'upload_test.txt' with some sample text on one node. Then, upload this file to file.io with a 1-day expiration. Print the file.io link from the result.

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script that first creates a small text file named 'upload_test.txt' with some sample text on one node. Then, upload this file to file.io with a 1-day expiration. Print the file.io link from the result."

Chunk 1 (source: NetUnicorn Library: upload Tasks):

```
Tasks from `netunicorn.library.tasks.upload` for uploading files from the node to various destinations:\\n- `upload.fileio.UploadToFileIO(filepath: str, expires: str = "14d")`: Uploads the local file at `filepath` to `file.io`, a temporary file sharing service. The `expires` parameter (e.g., "1d", "1w") controls expiration. (Uses curl).\\n- `upload.ftp.UploadToFTP(local_filepath: str, ftp_url: str, username: str, password: str, destination_dir: str = "/", timeout: int = 30)`: Uploads `local_filepath` to an FTP server at `ftp_url` using `username` and `password`, into `destination_dir`.\\n- `upload.ftp.RetrieveFromFTP(ftp_remote_filepath: str, ftp_url: str, username: str, password: str, local_dir: str = "./", timeout: int = 30)`: Downloads `ftp_remote_filepath` from an FTP server to the `local_dir`.\\n- `upload.googlecloud.UploadToGoogleCloudStorage(local_filepath: str, bucket: str, target_filepath: str = "", auth_token: Optional[str] = None)`: Uploads `local_filepath` to the specified
```

Chunk 2 (source: NetUnicorn Library: data_transfer Tasks):

```
Tasks from `netunicorn.library.tasks.data_transfer` for moving files between nodes after task execution:\\n- `data_transfer.SendData(filepath: str, task_name: str, data_type: Literal["ookla-speedtest", "pcp-speedtest", "iperf3", "netperf", "flent", "file"] = "file", local_filepath_is_temporary: bool = False)`: Makes the file at `filepath` available for fetching by other nodes. `task_name` is used to identify this data source. `data_type` provides context. If `local_filepath_is_temporary` is true, the file might be deleted after being fetched.\\n- `data_transfer.FetchData(send_data_task: str, endpoint: str)`: Fetches a file that was made available by a `SendData` task (identified by `send_data_task` which is the name of the SendData task in the pipeline) from the specified `endpoint` (node name or IP of the node that ran SendData). The fetched file is typically stored in the current working directory of the FetchData task.
```

Chunk 3 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.upload.fileio import UploadToFileIO
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Create a Pipeline
pipeline = Pipeline()

# Create a small text file
with open("upload_test.txt", "w") as file:
    file.write("This is a sample text for upload testing.")

# Add task to upload the file to file.io with 1-day expiration
pipeline.then(UploadToFileIO("upload_test.txt", expires="1d"))

# Get available nodes and select one
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "upload_test_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare, start, and wait for the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)
print(f"Experiment {experiment_name} prepared. Waiting for readiness...")
client.start_execution(experiment_name)
print(f"Experiment {experiment_name} started. Waiting for completion...")
client.wait_for_experiment(experiment_name)
print(f"Experiment {experiment_name} finished.")
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 9. Network Attack (LAND Attack - USE WITH EXTREME CAUTION AND ONLY ON ISOLATED TEST NETWORKS)
Prompt: Generate a script to perform a LAND attack against IP '192.168.1.100' using source port 1337 and destination port 80 on one node. (Warning: Only for use in controlled, isolated test environments).

### Retrieved Context:
Retrieved Context Chunks for: "Generate a script to perform a LAND attack against IP '192.168.1.100' using source port 1337 and destination port 80 on one node. (Warning: Only for use in controlled, isolated test environments)."

Chunk 1 (source: NetUnicorn Library: network_attacks Tasks):

```
`network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a JNDI lookup at `cc_address`.\\n- `network_attacks.loris.SlowLoris(host: str, port: int = 80, sockets: int = 150, https: bool = False, sleeptime: int = 15, slowloris_iterations: int = 100)`: Performs a Slowloris denial-of-service attack.\\n- `network_attacks.loris.SMBLoris(host: str, starting_source_port: int = 10000, number_of_ports: int = 1000)`: Performs a resource exhaustion attack against SMB (port 445).\\n- `network_attacks.mac.MACFlooder(iface: str = "eth0", count: int = 1000)`: Floods the network with Ethernet frames with random MAC addresses to overwhelm switch CAM tables.\\n- `network_attacks.mail.FakeMail(host: str, port: int, sender: str, recipient: str, subject: str, body: str)`: Sends an email using raw SMTP commands (potentially for spoofing, use with caution).\\n-
```

Chunk 2 (source: NetUnicorn Library: network_attacks Tasks):

```
port: int = 443, count: int = 1, length: int = 0xFFFF, tls_version: Literal["tls10", "tls11", "tls12"] = "tls11", starttls_proto: Optional[str] = None, data: Optional[str] = None)`: Tests for the Heartbleed vulnerability (CVE-2014-0160).\\n- `network_attacks.heartbleed2.Heartbleed(IPaddress: str, port: int, starttls: bool = False, debug: bool = False)`: An alternative implementation for testing Heartbleed.\\n- `network_attacks.icmp.ICMPRedirection(target: str, old_gw: str, new_gw: str)`: Sends ICMP redirect packets to `target`, instructing it to use `new_gw` instead of `old_gw`.\\n- `network_attacks.land.LANDAttack(target_ip: str, source_port: int = 1001, destination_port: int = 80)`: Performs a LAND attack by sending a packet with the same source and destination IP/port to `target_ip`.\\n- `network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a
```

Chunk 3 (source: NetUnicorn Library: network_attacks Tasks):

```
Tasks from `netunicorn.library.tasks.network_attacks` and its submodules, for simulating various network attacks. Use responsibly and only on authorized systems.\\n- `network_attacks.arp.ArpSpoof(target_ip: str, spoof_ip: str, interface: str = "eth0", duration_seconds: int = 60)`: Performs ARP spoofing between `target_ip` and `spoof_ip` on the given `interface` for `duration_seconds`.\\n- `network_attacks.cve202141773.CVE202141773(target: str, path: str = "/cgi-bin/.%2e/%2e%2e/%2e%2e/etc/passwd")`: Attempts to exploit Apache path traversal (CVE-2021-41773) against `target` using the specified `path`.\\n- `network_attacks.ftp.BruteForceFTP(target: str, username: str, wordlist: list[str])`: Attempts to brute-force FTP login credentials.\\n- `network_attacks.heartbleed.Heartbleed(host: str, port: int = 443, count: int = 1, length: int = 0xFFFF, tls_version: Literal["tls10", "tls11", "tls12"] = "tls11", starttls_proto: Optional[str] = None, data: Optional[str] = None)`: Tests for the
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.network_attacks.land import LANDAttack
from netunicorn.base.nodes import NodePool

# Credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Client Initialization
client = RemoteClient(endpoint, login, password)

# Pipeline Creation
pipeline = Pipeline()
land_task = LANDAttack("192.168.1.100", source_port=1337, destination_port=80)
pipeline.then(land_task)

# Node Selection
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Experiment Naming
experiment_name = "land_attack_experiment"

# Delete existing experiment if any
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Experiment Lifecycle & Results
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

## 10. Utility (Port Knock)
Prompt: Create a script that performs a port knock on IP '10.0.0.1' to port 12345 from one node.

### Retrieved Context:
Retrieved Context Chunks for: "Create a script that performs a port knock on IP '10.0.0.1' to port 12345 from one node."

Chunk 1 (source: NetUnicorn Library: utils Tasks):

```
General utility tasks from `netunicorn.library.tasks.utils`:\\n- `utils.network.PortKnock(ip: str, port: int)`: Attempts a single TCP connection (a "knock") to the specified `ip` and `port`. Does not return success/failure of the knock itself, always returns 0.\\n- `utils.sleep.RandomSleepTask(seconds_min: int, seconds_max: int)`: A TaskDispatcher that returns a `SleepTask` (from `basic.py`) which will sleep for a random duration between `seconds_min` and `seconds_max` (inclusive).
```

Chunk 2 (source: NetUnicorn Full Script Structure Example):

```
A typical NetUnicorn script involves: 
1. Importing necessary classes (e.g., `RemoteClient`, `Pipeline`, `SleepTask`). 
2. Defining NetUnicorn connection parameters (endpoint, login, password) - these will be injected by the RAG. 
3. Creating a `RemoteClient` instance. 
4. Creating a `Pipeline` and adding tasks using `.then()`. 
5. Getting and selecting nodes (e.g., `client.get_nodes().take(1)`). 
6. Defining an `experiment_name` (string). 
7. Deleting any pre-existing experiment with the same name (using try-except). 
8. Preparing the experiment: `client.prepare_experiment(pipeline, nodes, experiment_name)`. 
9. Starting the experiment: `client.start_execution(experiment_name)`. 
10. Waiting for completion: `client.wait_for_experiment(experiment_name)`. 
11. Retrieving and printing results: `client.get_experiment_status(experiment_name).execution_result`.
Example snippet for lifecycle:
```python
# ... imports, client, pipeline, nodes defined ...
```

Chunk 3 (source: NetUnicorn Library: network_attacks Tasks):

```
`network_attacks.log4j.CVE202144228(cc_address: str, hosts: list[str])`: Attempts to trigger the Log4Shell vulnerability (CVE-2021-44228) by sending a crafted User-Agent to `hosts`, pointing to a JNDI lookup at `cc_address`.\\n- `network_attacks.loris.SlowLoris(host: str, port: int = 80, sockets: int = 150, https: bool = False, sleeptime: int = 15, slowloris_iterations: int = 100)`: Performs a Slowloris denial-of-service attack.\\n- `network_attacks.loris.SMBLoris(host: str, starting_source_port: int = 10000, number_of_ports: int = 1000)`: Performs a resource exhaustion attack against SMB (port 445).\\n- `network_attacks.mac.MACFlooder(iface: str = "eth0", count: int = 1000)`: Floods the network with Ethernet frames with random MAC addresses to overwhelm switch CAM tables.\\n- `network_attacks.mail.FakeMail(host: str, port: int, sender: str, recipient: str, subject: str, body: str)`: Sends an email using raw SMTP commands (potentially for spoofing, use with caution).\\n-
```

### Generated Code:
```python
from netunicorn.client.remote import RemoteClient
from netunicorn.base.pipeline import Pipeline
from netunicorn.library.tasks.utils import PortKnock
from netunicorn.base.nodes import NodePool

# NetUnicorn credentials
endpoint = "https://pinot.cs.ucsb.edu/netunicorn"
login = "293nmay25"
password = "4Ij9Du65jrqj"

# Create RemoteClient instance
client = RemoteClient(endpoint, login, password)

# Define the pipeline with PortKnock task
pipeline = Pipeline().then(PortKnock("10.0.0.1", 12345))

# Get available nodes and select one
nodes = client.get_nodes()
working_nodes = nodes.take(1)

# Define experiment name
experiment_name = "port_knock_experiment"

# Delete any pre-existing experiment with the same name
try:
    client.delete_experiment(experiment_name)
except Exception as e:
    print(f"Error deleting experiment {experiment_name}: {e} (possibly non-existent, safe to ignore)")

# Prepare, start, and wait for the experiment
client.prepare_experiment(pipeline, working_nodes, experiment_name)
client.start_execution(experiment_name)
client.wait_for_experiment(experiment_name)

# Retrieve and print results
results = client.get_experiment_status(experiment_name).execution_result
print(f"Experiment results: {results}")
```

---

